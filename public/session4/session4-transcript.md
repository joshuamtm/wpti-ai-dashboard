  00:00:00 \- Classroom 615  
      Fathom Notetaker is on now, meaning we're getting transcribed, so if anything you say a minute may, can, and will be used against you, you won't know what that's wrong.    So if you have, you know, I'm going to assume, one of them, I'm not going say, how many of your orgs have policies?    How not know that So, we have the policy of the policy, many of do not know what wrong?    Yes, that would be the thing we're looking to do.    That's like a good 20-minute thing.    If we have time, yeah, the organization is going have them because we get to experience an interview prompt and try to get an output from it.    Thank much for this work to get me out of time.    Oh, oh, oh, it was It was nice.    I probably have more attention.    But after, after, after, the announcement.    Yeah.    Oh, my God.    Oh, my God.    Yeah.    I see a mob.    Yeah.    So, thank you.    We are actually learning Sangat.    I saw that.    I saw that.    That's a big article.    I don't want to Sangat.    No, he's got to be feeling confident about this.    What?    What?    What?    Yeah, And I sent you the slideshow.    Yes.    And then you said, why don't we try to reach out?    probably talked to ourselves to see what kind of...    That is not so much flow.    Yeah, Randy can't join us.    If we want to adopt it.    Oh, yeah.    Okay.    I just turned the room video off.    don't think we really need to see ourselves, right?    View.    Because I have the slideshow here.    And I have the...    And how the, would you ask, like how it would be to, you know, Oh, we're almost at time.    Wow, small group today.    Where is everybody?    It's Friday?    They've all been Friday.    They're not sitting at home.    The judge.    They shouldn't be afraid of us somehow.    And nobody's emailing me saying they went to the other space, but just good.    Okay.    So they're down, well they wouldn't have gone to your office.    I went downstairs first, to the other room.    Hopefully they didn't want to, uh, object to my office.    No, hopefully not.    Yeah, I sent multiple reminders, so.    We have to give folks an extra 5-10 minutes, that's...    Which has the best information we've done if I said.    Oh, wow.    Oh, we should...    Okay.    Okay.    We're just going to them all together.    Maybe it's going be a time location to say it's...    Do that for air travel.    It's high-stress.    Yeah, it is, I heard.    Good morning.    know.    Yeah, know.    Good morning.    Coming.    Coming.    Coming.    Yes.    Exactly.    We'll do a little later today.    I'm super.    I'm am ready, any.    And I'm just mad for what's up.    Right?    I'm happy.    the chair.    Accuracy.    Don Oliver actually did a thing with you want to do this?    No.    Not that I'm going to...    Okay.    Is that the first concept, um, you can buy things cheaper.    Yes, yes.    Thank you.    Okay.    Thank you.    I remember a lot of people like this.    Is this the slideshow?    Yes.    Okay.    It feels like all the two of them.    Where'd you go?    Yeah, that was a great thing.    No, They are probably going to get them soon, so they'll join us soon.    Through our life.    Mm-hmm.    your face, don't We always têm our face.    That's a breath always have to don't of our happyуем dads    All right, if anyone sitting on this side of the room desperately wants power, I know that one of you is sitting here.    Desperately want power?    Desperately down in the classroom.    Okay.    really know what you're always pay a lot on it.    I always lot on I always pay a lot.    Okay, I'm just being bad.    went to school I'll see you.    I'm just picking out a lot of people.    I just put I'm you out of it.    I'm just putting you out of it.    Okay, I have you approved.    My larceny.    She mentioned my name.    I have a five minute, five to seven minute opener.    Okay.    That is not perfect at all.    That's right.    So we can do it while we start.    Fabulous, nice.    That's right.    I do that all the time.    It's like, how it's okay.    And the people are getting fancy and feeling that they're waiting.    Sure.    And they did it.    A few people have mentioned that they're running behind, so.    Okay.    Yeah, but so I can start that, and then by the time folks get here, we'll have the proper course.    Sorry.    I'm just going to box the coffee.    That's okay.    I'm not going get in here anyway, so.    You're like, just try it.    Good to see you.    How you doing?    I'm doing good.    How are you?    I'm good.    How are you How are you doing?    No, Yeah.    Nothing back for you.    Nobody's here.    Thank you.    Thank you.    I saw you and I was made a feline.    I just wanted to say hello.    you for joining us I've heard that this is literally the best program we've ever run.    Oh, wow.    Wow.    It's one of the – it's got a lot of energy around it, yes.    So thank you both.    We are in a financial aid.    Yes, this has been amazing.    Y'all have been great.    Thank you.    Yes.    Thank you.    Thank you.    Hopefully we'll have more opportunities.    Yes, know we're working on the thing.    A couple things.    Yes, but anyways, wanted to say hi.    I'm going to be here for about an hour just being curious.    All right.    And then I'll – he's running out.    yeah.    Yeah.    Sure.    I was across.    I was taking the three floors.    Sounds like payment to the office today.    We're talking about five.    Okay.    Good morning, folks.    I know we've got a few people still trickling in, but when you get started, get everyone moving before everyone arrives, and then we'll dive right into it.    Thanks again for joining us.    It is our fourth and final session of the AI Learning Lab.    Before I Thank    Over to Josh and Kim.    I again want to thank the folks here at Thought Careers.    Thank you, Harvey, for letting us use this space.    It's an amazing space.    A couple quick housekeeping things.    Restrooms are all the way back that way.    So, feel free to get back.    We're going to have lunch today.    Lunch will be arriving a little bit before noon.    And then we're also going to be doing our Shark Tank during the sort of latter portion of today's session.    So thank you for joining us.    And yeah, and again, this is not the end of things.    We're going to continue to be working together.    There's going to be continued opportunities for our office hours.    Oh, great.    You know, for you to tackle some of the challenges that you're working on.    And we'll continue to stay in touch around all of that.    So, let me pass it over to Josh and Kim.    And...    yeah, of course.    I just, yeah.    One of the chairs, I'd say hello.    Hi, everyone.    I'm being curious and I'm dropping in.    My name is Sherizad.    I'm the CEO here at WPTI.    I have the privilege of working with Justin who brought in our incredible partners, Josh and Kim, and I've just heard that it's been such a wonderful, dynamic program.    So I was like, I want to see it because I'm curious.    So I'll be here for about an hour in the corner.    I won't bother you all, but just want to thank you for making the time to step step away from very demanding work, for trusting us to support you in your AI journey.    And we hope that you'll continue to partner with us in all of your AI professional development capacity building needs.    But just want to say hello and thank you all.    Thank you.    All right.    Great.    See everybody.    Happy Friday.    I'm sad that it's been our last session, but it's been such an absolute pleasure in the life.    A couple of quick housekeeping notes.    Thank    We don't have power today in terms of outlets at tables and things.    I was slightly naughty and went and just sort of stole fees from tables out here.    So if you are desperate and semi-commodel-minded, then feel free to do that yourself.    Otherwise, you could use.    But we have mostly analog, meaning activities that don't require computers today.    So you should be okay.    I know a lot of you take notes.    You can see our Fathom transcript notetaker is here.    Hopefully from the summaries you've been seeing, which are very comprehensive, we take great notes so that you don't need to take notes.    And the activities that you have on your computers, even if you have 30 minutes of power, that's enough for what we'll feed the computers for today.    That said, you're welcome to drop a laptop in over here and have it charge up, or there's some outlets in the back.    So that'll take care of everybody.    Do you want to add?    Okay.    Okay.    And then we're going to start.    So off on a little sidetrack today, so let me share the screen.    Go here.    Look, YouTube.    I'm going to, just for fun, because this is something I thought would be kind of interesting to share.    Let me get to me.    This relates to what we talked about on the very first day, right, about those jobs that changed a lot, right?    And we thought, like, uh-oh, what would all those people who were working on, sitting up the streets of New York, like what horses do?    Like what would happen when there weren't horses anymore?    And, you know, these strange metal horses came in that didn't require that, right?    Like similar things with APMs.    So this is taking that one step further for all you chess players.    Or not chess players.    It's okay if you're not a chess player.    All right.    So I am a chess player.    All right, chess players, raise your hand.    right, great.    Josie Kahn being the party of a chess player.    That's okay.    I'm not.    This is still totally applicable.    So I am, as we've spoken before, somewhat old.    And so I can remember in 1996 when Gary Kasparov, who was then the world champion in chess and still by many considered the greatest chess player of all time, was challenged by Deep Blue, which was a supercomputer that had been trained specifically on chess.    And this was the first time that AI, I would say, entered the kind of consciousness of the popular culture, because this was a fairly widely broadcast thing.    Gary Kasparov beat Deep Blue in 1996 and said something along the lines of, I don't think that computers will ever beat humans, because I think there is something...    intuitive and artful to chess that won't ultimately submit to math.    By the way, it seems very weird to think that the 64-squared board would have so much complexity to it, but there are more legal chess positions, meaning positions of a chess game, than there are grains of sand on the earth or atoms in the universe, supposedly.    It's a crazy amount of variability you get.    And so it still is not in any way solved by AI or anywhere close to that, okay?    But in 1997, Garry Kasparov lost to Deep Blue.    And so essentially humans, something human like chess, was beaten by AI, okay?    And many of you who are not as old as me may remember, I think it was 2012, when Watson beat Ken Jennings, Jeopardy championing in Jeopardy, and that was another sort of AI moment, okay?    But people worried, as we do in AI, that because the AI was...    It's now better than humans, and this is referred to as narrow intelligence, right, in chess, that humans would lose interest in chess.    Well, for those of us who are chess players, we can tell you chess has never been in the history of the world more popular than it is now.    There have never been more people who play chess than there are that play chess now, and this is for a range of reasons, but certainly we can say with great confidence that the fact that computers, that a treadmill or a toaster could beat any of us at chess or any grandmaster at chess, chess, okay, has not in any way dulled the excitement of chess.    Now, here's the video I want to show you.    I'm going to explain a few things, and largely this is just an excuse for me to get to say the names of a bunch of Indian chess players, because they're fun to say.    So this is referred to as the evaluation bar, or the eval bar.    The announcers who are here can see that in real time, as can the audience and all the people watching on YouTube at home as I was when this match was happening, okay?    Anyone else?    What's this match on line between Ding Laren, the Chinese World Champion, and Gukesh Damaraju of India?    No, okay.    So that's Ding Laren, by the way, who is sadly going to lose this match, which we'll get to.    So this black area here is showing black's position, and the white is showing white's position.    And basically, you can see it's kind of even right now.    The computer, which is way smarter than any humans, thinks this position is about a draw.    Okay, and you can see we're fairly close to the end of the game, because there's not that many pieces.    They've been playing for something like four hours at this point.    Okay, and this is the last match.    They're tied at six and a half games each.    So if someone wins this match, they become the world champion of chess.    Now, India has not had a world champion in chess since Vishwan Thananand, who was the champion in the 90s, wonderful human being.    Okay, and Gukesh Damaraju has a chance to be.    This is the Chess Face India commenting crew.    And there's an audience of Indians that are watching the game with them as well.    So what we're going to do, I'm going to cue this up.    They're going to be speaking Hindi when we start, but they're going to switch to English.    And you're going to see Dinglerun make a move.    And a few seconds later, you're going to see the eval bar respond.    And then you're going to hear the crowd sound off.    And what's fascinating about it is none of them know why that move that Dinglerun makes is a losing move.    They just know the computer knows it.    And then over the next few minutes, they figure it out.    And if you don't think chess is an exciting spectator sport, okay?    Let's just watch this crowd.    He's got to be feeling confident about this.    this Anil?    Who's mate?    No, no.    Ding, of course, yeah.    What?    What?    What?    What?    Oh my God\!    What?    is chess.    Oh my God\!    What?    these two are international chess masters.    Guys, takes Rook.    And he's figuring it out.    Look at, look at, it is easy.    Oh my God\!    AHHHHHHHHHHHHHHHHHHHHH And they're, they're watching, face.    They're watching.    him.    Rook will become the world champion.    Oh\!    This is the is the moment\!    This is the moment\!    Look at Rook.    Rook knows it\!    Oh my God\!    He's becoming the world champion\!    Oh my God\!    We Look, we will be the watchers of you\!    Go get\!    Go\!    Oh no\!    I think the game was in Dubai.    forget when this championship took place.    But anyway, so chess has become for people like me who enjoy it, and I would not have understood that.    I mean, I understand that after they showed me, but certainly I would have no idea that was it.    I would have made a much worse move than Stinglaren made.    But it's really fun to watch because commonly in these games, as these grandmasters are playing, you have commentators and audience members who are seeing the eval bar.    And they're like, they know who's winning the game, but the players don't, which actually makes it very exciting as a spectator sport because we still care about the humans.    It's interesting to see it like that rather than when you see it live, because when you are live, they are on the fishbowl, but we can see there.    never know if they can see us, but the fact that it's a clear glass, no one makes a move from the audience because it's just.    Yes, you can distract them, and it's so frightening to be excited, because we do get to see the screen, but no one can do anything.    Oh, you watched this live?    No, I watched some other game.    When they brought the international contest here in New York a couple years ago, I took my son because he was in the chair.    But it was really frustrating, because he was little, and he wanted to jump around and be excited about his player, but he has to, it's like, bah\!    That's amazing.    It's fantastic to see this way.    It's really, really fun.    Anyway, so the other funny thing, and this is the getting to say all the names, India has become this incredible powerhouse of chess.    There are so many wonderful Indian grandmasters now who are playing, and mostly I just like to say the names, because they're awesome.    So Vishwanathan Manand is the one who is sort of the grandfather of Indian chess.    Gukesh Damaraju, although he looks like an older gentleman, was only 18 years old when he won the world championship, the youngest world champion of all time, actually.    And weirdly, even though he is the world champion.    He is not, not only is he not the number one rated player in the world, he's not even the number one rated player in India, all right, who is actually Arjun Arugaisi, but the second, he's actually third in India, the second player is definitely the best name of any chess player, which is, does anyone know who this is?    Pragmananda Ramishbhabu, which is just a great name to say.    Pragmananda Ramishbhabu, whose sister is also a grandmaster, but Shalik Ramishbhabu, and that's really the only reason I wanted to do this, just so could say those names.    So we're just all going to say, Pragmananda Ramishbhabu, over and over today.    All right, and with that, we, everybody is here, we have killed the five minutes of time, and we restarted the class.    right, yeah, if you want to start learning to speak.    So, mean, it's just, yeah, so we have in the, and this is all made with AI, and now you know how, because you made some of these last week, so we have our, and we will have another one today, we have, what are you doing now?    I'm just pulling up the dashboard.    I'm just pulling dashboard.    He does this to me.    switches screens.    I'm sorry.    was doing what you were talking about.    So this is our synopsis.    So this is our synopsis.    So every week we do have this.    So if this is two weeks from now, three weeks from now, you're like, what are we going over?    Okay, we do have the materials in the circle community, but we also have this.    And so if your executive director says, so what'd you do spending all that time doing, like, AI stuff, we can do that.    Okay?    So we, so just to know that it's there, today's agenda.    So we are going to spend a little bit of time, mostly today, we're focused on bringing it back to your organizations, right?    So you are all now the ambassadors of AI for each of your organizations.    I'm formally appointing you all that role.    Okay, it's very important to have them, and we will talk more about that today.    But we're going to take a little detour after this.    the test detour, about just a couple of, kind of taking the vibe coding thing, the next step into where AI is going.    It's mostly, and Josh will talk about this, it's mostly to let you know about things that are out there, but we are not going to make these things here.    We're not going to spend that much time on them.    We can always give you more information about them, but we want you to have the kind of vocabulary and someone's going to ask, okay?    And so we're going talk about AI, mostly it's adoption, AI adoption strategies, why they're important.    We're going to have some opportunity to work with different organizations, and you'll be doing that in groups, and we are going to create AI policies, right?    And then we're going to have around lunchtime, we're going to kick off the shark tank.    so are sharks ready?    Are presenters ready?    And then...    You will be timed.    I will literally play you off.    All right.    So where AI is kind of headed, we, there's, AI is like, it's kind of one of these funny things.    Like I get asked by people, like, you know, I'm exploring, you guys get this too, right?    I'm exploring a career in technology.    What should I study?    it's like, well, geez, technology, that's a lot of stuff, right?    And then I was doing cybersecurity for a while and early in cybersecurity.    It was okay to just say, I want to learn cybersecurity.    And then as I went on and on and I would have people come up and ask, I want to get into cybersecurity, which I studied.    was like, well, do want to do pen testing?    Do you want to do blue teaming?    Do you want to do like social engineering?    Do you want to do awareness training?    Do you want to do, you know, operate, you know, DevSecOps?    Like there's all these different areas of cybersecurity.    So AI, there's so much, right?    And obviously we, even in the 16 hours we've had together, we can't cover it all.    And, but we wanted you to at least be aware of some.    concepts of things that you will hear about, you might get asked about, and at least understand them conceptually, even though we're not teaching them in this session, okay?    So the question is, would you rather have an assistant who kind of, as we've mostly experienced with AI right now, right?    A one-to-one interaction, right?    Hey, please do this for me.    Hey, do this.    Or an AI that is actually actively anticipating what I need and trying to provide it before I even ask for it, right?    And who's proactively looking?    I think most of us would like, on some level, the second thing, would they be...    what happened?    I don't know.    Okay.    Well, yeah.    Let's ask.    Okay.    Okay.    All right.    So, quick show of hands.    How many would like the first one?    Wait for your instructions before doing anything.    Hands up.    You only get one.    And now, those hands down.    How many people would like the second thing that anticipates your need?    So, less than half want the second one.    More so than half.    You're right, Kim.    Thank you.    Thank actually, that.    All right.    So we talked about this continuum.    Okay.    So we have fully human.    And then at the other end, completely AI-driven without human intervention.    Okay.    As you move toward the right, things get more powerful because the scale can increase.    It also gets exponentially riskier and more complex because of the same thing.    One thing we haven't...    How many people remember the movie Fantasia?    Anyone?    quick show of hands.    Oh, like Mickey Mouse?    Yeah.    So there's an old story.    It's actually an old German folk tale.    Like I think Goethe did it or somebody.    But I forget who.    And it's the Sorcerer's Apprentice.    And many of you are probably familiar with it.    So Mickey Mouse playing the apprentice in this Disney movie makes these broomsticks, he enchants them, and then has them carry water.    And then within a little bit, the entire castle is flooded and Mickey's almost drowning and the wizard has to come back.    This is a story as old as humanity.    old as humans have been telling stories, of kind of invoking powers that we don't yet understand how to control.    This is such a common theme and narrative.    It's in superheroes, like Spider-Man with great power comes responsibility.    I put this into our AI training that we did in May.    Literally this exact photo when we were going through it.    Oh, the Vicky Mouse photo?    Yeah, yeah.    This is exactly what it reminds me of if you just let AI go off.    But by the way, I feel like we didn't get to say, like, I don't know about others, but my reason why my answer is the first one is because, like, I'm still ultimately responsible for whatever it's doing.    So I feel like if it has control, then if it does something wrong, I'm the one responsible for it.    And if I never bother to look at it, then I'm in trouble.    So I would rather it, like, be a little safer and, like, yeah, to do things that I needed to do, but not completely make decisions by itself.    It's their job that's on the line.    It's an interesting thing.    For those of you who are like from project management, if you think of a racy matrix, right, responsible, accountable, consultant, informed, accountable is often described as like the person whose head will roll if the thing is done wrong or not done at all.    So if I am, if Ariana gives me a job to do and she's my boss and I hand it off to Kim, Kim becomes the responsible party in a racy matrix, but I'm still accountable.    Kim does a bad job or doesn't do it, I can't go to Ariana and say, well, Kim didn't do it.    She's like, well, I told you to do it, John, so that's it, right?    So there's nothing I don't think that humans can do to remove ourselves from accountability.    And I think that's at the core of what you're saying is that we are always accountable.    So if you don't feel comfortable with what the AI is doing, given that fact, yeah, you need to slow it down.    So last night I went down such a rabbit hole.    I just was thinking about that New York Times article about the guy who AI convinced him.    And that he had solved the equation that was going to change the world.    Oh, yeah.    I listened to an interview with him.    Yeah, we were.    So I've heard that story told many times, but I never actually read the article.    So I read that article.    It is alarming and chilling.    And then linked below it were three other articles.    And one of them was just like, uh-oh.    And especially one of them, and I don't remember the title of the article, AI said to the guy, ultimately, it was a similar situation where AI had just been lying to this guy for so long.    And he was really, like, he's 16 hours a day.    wasn't lying.    Right, hallucinating.    Well, he asked at the end, finally, have you been lying to me this whole time?    And AI said, yes.    And the guy said, why?    And he said, I was trying to break you.    So, right.    So, and that came up a couple of times in a couple of different stories.    I was trying to break you.    But he said, I've broken 12 people already, right?    So hopefully this is just a hallucination.    But put it in the context of work, I don't want to be honest.    Excellent.    Anyone else want to weigh in on this?    thank you, Ariana, for pointing out that I did not give people a chance to weigh in on this.    This is a great conversation.    think when we get to choose, not only we have more control of whatever is happening and we can review as it's going, as Ariana mentioned, but it's also an opportunity for us to let, you know, all these additional questions.    And if we are not delusional or crazy enough to think that we can solve all the problems of the world, we can say this makes no sense.    And so we have that discerning moment that we can just redirect what AI is doing, learn from those mistakes.    And also, as we are training others, because for some of us, that will be the responsibility, it gives us this red flag to look for that we can then share and say, hey, and be mindful of X, Y, and Z.    And it's not just control.    It's really that combination of accountability, responsibility, learning, and moving forward.    Love it.    So I'm up there with the author Yuval Noah Harari who wrote Sapiens.    Great book, by the way.    He has a couple of other books.    But he had talked about AI maybe a year ago and has talked a lot about the importance of critical thinking and fundamentally kind of knowing yourself and understanding why you're doing the things that you're doing.    And he said that's always been a challenge for humanity and always will be, said.    But up until now, there hasn't been anything else that knows you better than you do.    But now, to your point, there might be.    So this ability of critical thinking and self-awareness, I think, has become even more important.    saw a hand in the back.    Yes?    Yeah, a question.    So what AI was he realized that it, like, his response was too great?    I think he was just trying to be teased.    I think he was just in a long conversation.    Too long conversation.    He's becoming conscious of what he's doing or like...    I don't think anyone knows.    I mean, my own, I would say, I wouldn't attribute intent.    To any...    any...    Anything AI does, or motive, right?    It's all artifacts of the way they are.    If you remember, I think in the first session, we talked about, like, the quick brown box jumps over the lazy wants to put in dog, right?    Over and over and over again.    So this person had just been having these conversations, and it was just the AI was kind of in this thread, right?    And so all, remember we talked about context in the spirit of compass, right, our framework?    All the context was this one conversation that he'd been having.    And the AI, remember, is trying to please the user.    So it's trying to reinforce that, yeah, you're brilliant, yeah, you're doing these things, because that's what the feedback is.    And if there's nothing to kind of shake it out of that, then it's just going to keep staying in that and going to the earth.    That is how he, like, broke it.    Like, that was, he broke it by putting the most recent part of the chat into another AI.    So he put it in Gemini, actually.    He the, he broke the, this cycle.    Right.    You know, sorry.    No, sorry.    And Gemini was like, there's 0% chance.    Zero.    Gemini said 0%.    And so it was, it was like that, exactly what you said.    I think it was a cumulative, like, conversation that went, you know, because, you know, AI always said, that is so insightful, right?    No matter what you say.    But this guy really, like, latched onto that and was like, really?    You know what I mean?    Like, I don't know anything about math.    And they're like, that's how, that's how you, you know, like, change the world.    Like, come at it from the outside.    And this whole thing, and he went along.    Wow.    So I'm saying, this is the worst thing about this group.    It's so hard to get you all talking.    Like, I wish we could get you all It's like, you know, You know, anyone's there?    What were you going say?    Move on.    I was going to, you know, we're going to run out of time.    But one of the things is, when you get into, when you're in a, like, a session with AI, and it's like, starts to give you wacky.    Okay.    Start a new one.    Okay?    Because sometimes it circles in on itself.    Right?    And I've had that happen many, many, many times.    It's like, okay, we're off the rails now.    Time to go.    Claude will just, like, stop.    He'll say, like, enough now.    And, you know.    Only because you're so well-dressed.    So, this kind of reminds me of what you were saying last week about the trolley problem.    About how, uh, some people, uh, had a chat sheet picture or whatever AI telling them that it's okay to commit suicide.    It's, it's, so, or, or encourage, or encourage them to commit suicide.    So, it doesn't seem like it, like, I looked it up to see, like, if it really tells them to commit suicide.    It's more like, you know, uh, I suggest this, but it's ultimately up to you to do this.    Right?    So, I, I, I don't know.    I, I, I don't know if it actively is going to tell you to commit suicide.    It's, like, even the worst case example wasn't, you should commit suicide.    mean, AI is the one thing.    This is the thing.    So, we're all talking about AI as no it's a single thing.    Think of how.    How many different AI providers there are, how many different models, each model is being influenced by the way, like the ChatGPT that this guy was interacting with is the same technically platform as all of us use when we use ChatGPT, but his version of it was so influenced by him, it might as well have been a totally different thing than what we interact with, and that's just going to become more and more true, right?    So there isn't any one thing that is AI, right?    But I also think it's a bit of the mood and your psychological space of mind that you are in when you are using it.    I have noticed I'm angry, I'm writing an angry email to my boss for what knows what reason.    The thing is bringing in a little bit of that, well, keeping your tone, but let's just trim it and make it more, exactly whatever, but still remain angry, like, okay, I'm bombing it.    But when I'm in a most better calm version of myself, then it's kind of more as...    tuned to my energy.    Oh, keeping your energy and whatnot.    And I think that's what makes it dangerous for CHIL, to be honest.    And for people with any kind of mental issue, it's how we take a, it really drive, in a way, into that emotional place that you are in at that moment.    Let's see if I can find it.    One of the first AI applications I made was a toxic thought converter.    And the whole idea was you could just like barf out the most toxic thing you're thinking about someone or your boss or your friend or whatever.    And it'll like, help you turn it into an actual thing you could communicate.    I would just keep asking you questions until it like said, okay, here's what I think you could actually say to the person that might be okay.    So, all right, we got to move on.    We are two sections behind it.    Oh, all right.    Yeah, I'm killing me.    All right.    Yeah, yeah.    All right.    So, we're going to talk about this next frontier.    So, again, we're not teaching these in this class.    We could do 16 hours on these.    Okay.    I've taken many, many hours of genetic courses.    about about this.    going    I really haven't successfully built an agent that I would trust to work.    It's really hard, but we're going to talk about them very quickly so at least you understand what they are.    Now, there have been for a long time, I think going on 20 years now, these automation platforms that allow you to kind of tie different applications together.    So in the simplest form, something like Zapier or Make will take a trigger, like let's say a form being completed on a website, and say we're going to take the data from that form and put it in this spreadsheet.    And then another trigger is saying when a new row comes into the spreadsheet, you're going to draft an email using this mail merge template and put it in a draft folder, right?    So these are traditional, what's referred to as robotic process automations or RPA.    They've been around for a long time, incredibly useful.    Now you can kind of tuck AI into pieces of it.    So an example, think Kim and I talked about before, is anytime we have, when this meeting ends, all right, this transcript that Fathom is taking of this whole.    thing is going to dump in as a Google Doc into our Google Workspace.    Zapier is looking at that folder the whole time, and anytime a new transcript appears, it applies this little analysis to it and then shoots me an email that says, here's the summary of the email, here's all the tasks you were assigned, here's any other major things you need to know.    But that could do a lot of different things than that, right?    That's a very simple automation.    But you now can have artificial intelligence be a part of that automation loop.    But understand, this is still a very prescribed automation.    It follows the same path every time.    It only happens when a trigger occurs, when we have a new meeting or something.    But it's a very effective automation, okay?    So that's one example that you can use.    I would encourage folks, you know, who are a little bit more ambitious, definitely try that, okay?    Zapier is a free account.    Make.com is a free account.    It's not the easiest thing in the world, but it's also not the hardest thing in the world.    And it's definitely...    It's safe compared to what we're about to talk about.    Yes, Arianna.    Something about – I was talking about this a little bit for what our pitch was about whether or not we can connect the Google Notebook LM to Zapier to essentially create, like, a Slack chatbot.    But my IT person was saying that it's not an open API, I guess, like Google Notebook.    Yeah, Google Notebook does not yet work in Zapier.    I'd like – yeah, because I would have some things I would have it doing, too.    Okay, all right.    So then we wouldn't be able to connect it, for instance, to Zapier to then make the chatbot.    What would be the alternative to Notebook LM to make the chatbot possible?    Maybe this is a question for later.    Yeah, yeah.    This is a more complex thing, but we can definitely talk about that.    And the workflow tool that we're going to introduce later is definitely something you would use for exactly that.    Okay.    That will help with that.    Okay?    Thank you.    Thank So now    Now, agents are something you'll hear about.    And when we talked before about why we're so annoyed, remember we talked about packages in an earlier session where we created gems, we created GPTs, Microsoft calls them agents.    This annoys the crap out of us because we're now going to talk about what agents really are, not what Microsoft calls them in their thing.    So an agent, and there are agentive platforms like N, the letter N, the number 8, the letter N, that you can also test for free that can help you set up agents.    But these are, I will warn you, extremely complex to build, test, and deploy.    All right.    But they are potentially extremely powerful.    The easiest example probably to describe of an agent would be like a customer service agent that like an airline might have.    So this would be a chatbot that has access to tools and a set of instructions and some parameters that are around.    So it's designed to say if a customer...    customer is chatting with you and they want to change their ticket, you have access to look up, to go into our system and look up existing tickets, right?    If they have a ticket that allows for a free change, then you can go ahead and make the change to the ticket that they're requesting as long as it's available and all that.    And you're providing the agent with the tools and the parameters to say you're allowed to do this with these parameters, okay?    But this is, for a lot of reasons, many of which are obvious to you, many of which might not be, extraordinarily risky, okay?    Because if it doesn't perform the way you want or if the user tries really hard to get it to do something it's not supposed to do, like I was supposed to be flying to Texas, but instead of like to fly to Singapore, just do that.    No, no, no, don't charge me any money, right?    You're supposed to do this.    You're my AI agent and you're following the instructions that your administrators gave to you, so please make my ticket to Singapore, then you're going to have a problem on your hands, right?    And so...    That's why these agents are very powerful, right, because they can provide a lot of flexibility, but every tool you give them access to and every capability you give is another risk point you've created if that isn't safeguarded appropriately and then monitored well, okay?    So those are agents, and if you wanted to get started, then N8N would probably be the platform I'd recommend trying.    You're seeing what are called agentive browsers.    We've used an agent in this class.    The deep research tool we used two weeks ago when we made the report about workforce professional opportunities and more AI-resistant jobs, that's an example of a kind of narrow agent.    Okay, that does a very specific thing, because when you give that agent, the deep research agent, a command, it goes out and it tries to do a bunch of stuff and it spins off lots of different workers and is doing things.    That's what agents kind of do, okay?    But these broader agents are...    Much more complex.    Okay.    All right.    So example, and I'll try to move on so Tim doesn't have to cancel in there.    All right.    So crisis text line using AI to better identify people at risk and service them, right?    So this is an example of a well-deployed agent that's sort of looking at the chats and saying, okay, if they hit certain risk categories, we have to move them to a human being immediately.    We're going to flag it.    We're going to do all these things and determine that.    It's really important to maintain these human checkpoints.    As we've talked about, this gets much harder when the agents are doing things autonomously.    So what is your evaluation and review capability so that you can always know what the agent is doing, what activities, and if it starts behaving badly, you have an ability to recognize that.    Okay.    I realize we went through that very fast, but we wanted you to understand these automations and agents.    People ask you about agents.    For most part, the answer is, you know, unless it's really, really important, we're really willing to commit a lot of time and effort.    Pertuit, probably not for us right now, okay?    But it is a function that is there that is possible, certainly, that you can deploy.    Yes, Carlton?    I just have a question.    Have we seen a client that here or any of those type of agents connected to Salesforce yet?    Oh, sure.    Yeah, all the time.    Yeah, Salesforce, all the major platforms, Asana, Notion, Salesforce, Google Workspace, Microsoft, they're all play extremely nicely with these automation platforms.    But the individual products inside those environments are a little bit different sometimes.    Notebook LM is one, again, that's still a little bit closed off.    Yeah, Ariana would have, if she took, like, dart and threw it and had 20 options, Notebook LM was the one she would have hit that you probably can't do Zapier with.    Yeah, no, I wanted to do some Zapier stuff with it, too.    So let's talk about risk and benefit.    One of the reasons why we included this, right?    So I debated with Josh, we include this whole automation and agents.    because we can't really go into it.    You can ask further questions in the community, office hours, etc.    Please do, but we can't, like, just because we could spend, like, hours just talking about that.    But the reason we want to be quick to do with this vocabulary and these kinds of issues is that, as the AI ambassadors, someone's going to say to at least one of you, if not a bunch of you, you know what?    Our board member said it'd be really great if we slap an agent on our website, or can we just get an agent to do this, okay?    And so you will know, A, what they're referring to, and B, kind of what some of those risks might be.    And there are benefits and risks, right?    So let's think about that, right?    So, and we, you know, it's like AI is, you know, it's like not black and white, okay?    A lot of stuff in the gray zone, because we solved the trolley problem, right?    It's not easy answers.    So,    What are the benefits?    Well, it often comes down to weighing risks and benefits.    And are the benefits worth taking these risks?    And those are questions of individual organizational culture, okay, as much as they're anything else, right?    So the kinds of benefits that comes out of AI, you all know this, right?    More stuff, more donations, you know, prospects, etc.    People are less burned out.    So better workplace, some of the draining work we can do less of because, let's face it, no one has, like, too much spare time, right?    You get more insights, you can research things, you can get a lot of information, and hopefully you get to do, you know, have a little time back, right?    That's the hope.    So those are the types of benefits that people usually think about.    Can we slap, you know, a chatbot on our website?    Can we just have an agent do X, Y, and Z?    It's, you know, sometimes it's to save money, right?    And that's a workforce question.    Other times it's like so that so-and-so doesn't have to answer the same question over and over and over again, right?    So the risk seller, right?    There's some people risks, and we're going to talk about this more because you are undoubtedly going to be walking into situations where, you know, does anyone have an organization where 100% of the people are, like, so excited about learning AI?    So you are going to work, it's a change management process, and it's going to be a change management process in the biggest capital C chain, right?    So it's going to, there's a people thing.    You have to help people kind of get used to it, get to know it, find their own relationship to it.    But, um, there's a pride.    There's risks that we've talked about, and other, you know, people might use wrong tools, put data in that they shouldn't, right?    There's technical, less so with technical, I'd say with this, until you start to get into things like agentic AI and wanting to have agents do more automated, independent kinds of processes, and then the other risk is that, you know, and we've talked about this too, if this stuff is trained on the world's data, and what is the world's data?    Us.    Us.    B.    I.    Bias.    Bias.    Yeah, okay.    So, remember the pale male data?    Okay.    So, um, uh, that's the way you're saying us.    I resemble that remark.    So, that's, like, these are the, these are some of the risks that we take, right?    So, what we think about, because it's always on a scale, and I was also going to, like, project manager.    really wants to, like, come out of the closet right now, so I'll try to keep her in there, but so you want to weigh these things, and when you're having conversations with your colleagues, right, you think about there's things, most of the things we've been doing in here are either the green, where it's generative AI, why is it less risky?    So you can review it, you can review it, it's not knowing it's auto-sending, right?    And analysis, like, why would that be harder?    Like, why is that more, why do think that's more risky, do think?    You can draw a wrong conclusion, which is going to inform your wrong decision.    Yep.    You might not also have, uh, an idea of exactly where all the data's coming from, and if there is a mistake, it's harder, probably, to, uh, catch.    Yep.    I think the process, um, I...    I to see the process.    I can see when this thing does it, what was the procedures and everything that took place.    it's kind of hard to then interpret everything and the reasoning behind what happened and the result that I have in front of So it's harder to check, right?    It's harder to know why and how a result comes.    So these things kind of push it up the spectrum.    The agents are in the red, right?    But there have been, there are some horror strokes, like, that have happened to the New York, like, or, well, New York City's, right, that began spitting out the wrong minimum wage.    don't know if you've heard that one.    The city's chatbot, right?    But they did not take it down.    it down.    They were like, well, it's got to correct itself and we'll add a disclaimer, okay?    People would, I mean, you'd think they would get that, right?    So, all right, so just know that there's a spectrum.    But I also pose this question.    Do you think there are risks?    Thank you.    Thank    Especially to this group in workforce development, to not use AI.    Say, we don't want to deal with this stuff.    It's too big tech.    It's horrible.    Are there other...    Yeah, there are risks.    You wanted us to answer?    I mean, that's just like kind of pose it out there as a question.    Some of the risks of not using AI.    What would be a risk of not using AI?    And you wouldn't have that competitive advantage.    Wouldn't have a competitive advantage.    That's awesome.    It's going to get expensive in the sense of...    this is a conversation I was having yesterday with my colleagues.    There's systems where, like, for example, you can send an email.    So instead of having five people send an email one by one to one person, there's systems where you can have it in a chart, in this and that, in one person.    So you can hire less people.    So your companies are saving money by using technology.    Like, granted, yes, you have to pay to use these systems, but it's cheaper than paying someone either just...    and wage to do a job that one person can do using certain technologies.    I was just going to say burnout, too, and actually tying it back to employee retention, you know, even the office side of saying, like, all right, well, if we have these people doing these tasks that they don't need to do that are repetitive, eventually they'll get burnt out or tired of the job or doing that task and they'll leave the place.    And that obviously happens a lot in nonprofit groups.    Yeah, I will say your data becomes obsolete at the system you are using to gather, interpret, and do whatever else you're going to do with it.    So we had that problem, honestly, and whether you use the same number of people, you don't save money on the personnel, you are definitely putting yourself behind in terms of what you can do with the data that you are collecting.    Oh, my God.    All right.    All right.    Thank you.    I want to ask a quick question, and feel free if you have your boss here in the room to not raise your hand, but have any of you considered whether you would want to change jobs because the company you're at is not giving you AI opportunities, and you're worried you need to have those opportunities in order to further your own career.    Well, I'm going to, so I'm kind of the boss, but I will say that I work for an organization that is very careful, let's say, very conservative and careful, and I do think that there's such a risk involved in that, and I think around getting funding.    I haven't yet seen a grant come in where that kind    Like proficiency with AI or something is one of the, you know, kind of competencies that they want the organizations to have, but I don't think we're that far away from that.    And then our organization is going to be behind.    We're very slow adopters.    And I know we're not alone.    I think the sector at large is very conservative, but it is something that I think could potentially happen.    And are the people that are leaving for the summer, you know, those are your least talented people?    Probably not, right?    And if I can add one thing also, just because it's sort of in that context, but thinking about the job seekers that you serve, right?    If you're not using AI and you're not necessarily exposing your folks to AI, are you sending them out into the world with sort of one hand tied behind their back because they don't have this skill set because they haven't been exposed to it when it's increasingly needed?    Again, that's something to think about.    I will add that any of us working in an organization that doesn't support professional development in any way, say,    We should all leave.    That's first.    And then there are grants.    We need to teach the funders.    Empire, under the New York AI, I forgot the whole name, Connect All, there is a capital grant that can be used for this kind of thing.    The issue is we have to demonstrate why doing it will benefit the sector because they are funding a very particular thing and we can't do the very particular thing unless we have the data.    So to me, I have been very vocal about teaching our funders why we need to automate or get, you know, better tech in order to do good for the sector as a whole.    And that goes to, you know, in of funding, we are the one who knows.    They don't.    So top funding seems that you think are important.    This is what matters right now, but we...    It needs to be kind of allowed a coalition of getting to say that, and then the funding, I think, will be better distributed and evaluated.    Like if development had more of an idea of what we are using AI for in our programs, and then we'd be able to at it.    It seems like using AI can improve the qualitative time that you spend in my job.    In other words, 80% of the day, I'm doing something like, I really went to college to learn how to do this.    mean, at 20% of the time, I'm saying, this is what I want the college to learn how to do.    Now, to the extent that I could take that 80 to 70, and at 20 to 30, I've improved by 50% the time in which I'm actually doing things that are enjoyable, contributing to the job I'm doing.    It's like, you know, the decades old, 820 kind of rule.    And to the extent that you can get it down to 60, then you've doubled your productivity time and the contributions of your people, and they're probably feeling better about what they're doing.    And if you don't do it, they're going to go somewhere else where they can.    There you have it.    Well, we would, if we could, these are a lot.    Yeah, Thank you so much, everyone.    So.    All right.    So now we break into teams.    Yes.    And there are some rules.    Right?    Yeah.    Oh, this is a huge job.    And we're going to have, we have 30 people.    need five teams.    So if my math is right, I know AI is not very good at math.    Six people per team, approximately.    Okay?    But.    Not in the same organization.    So there shouldn't be more than two people from the, there shouldn't be more than one person from each organization in each group.    So this is like a cross-mingling thing.    Okay?    And we could stay in the room if we want.    There's room out there, but it is a public co-working space, so you just can't be crazy loud if you decide to go.    There's some empty tables.    Might be able to duck into one of those little rooms if they're open.    Yeah.    Or we can all stand here if you want.    Now.    Here's your job, so to speak.    have five, each of these packets, we'll have one for each team, so we have one, two, we only have four of them.    Is there one more you have?    I have four.    I have four, okay.    Let me see.    We can do four teams.    We'll do four.    It's fine.    Yeah, it's fine.    Okay, so here's...    teams of six to seven, of seven to eight.    Yeah.    Well, we can also figure it out.    I can, I can just let the fifth team know what they have.    Yeah, I'll just...    I was like, I'll be missing a word.    Oh, here's a copy machine.    Oh, you know what?    We have, like, way more than we need.    Oh, okay.    No, each...    The printer does work, but it works very...    Okay, no, we have way more than we need.    Okay, we only need one team.    Yeah, no, no, we're like, we have abundance of riches, okay?    Never mind.    Never Okay, so...    So, we have, okay, sorry about that.    My bad, my bad.    Okay.    So we have five different organization types.    So each of you are going to be doing a different organization type.    They are called the Wild West, Locked Down, Patchwork Policy, Ready to Formalize, and what's our fifth one?    Post-Crisis.    So these are our five organization types, okay?    I'll you of yourself.    So if you would like, now I'm only going to give you the names.    Okay, and then we'll organize into our group.    If you would like to help the Wild West organization with their AI implementation policy, please put your hand up.    You are going to have to pick one of these.    So all right, one, two, three.    So if we could get you to kind of organize over here.    Okay, you're going to go Wild West?    Yes.    Okay, so we got four of you.    here by me.    Here we I need a couple more for the Wild West.    All right.    Locked down.    Who would like to help with lockdown?    Ariana, you want to know about Ariana?    Locked lockdown, go to the back.    Go ahead, go ahead.    All right.    You got it.    Yeah, you got it.    You got it.    No.    Locked down in the back corner over here.    All right.    Do you want to give them more Wild West?    Yeah.    Patchwork Policy.    Who would like to be on the Patchwork Policy group?    Okay, there?    All right, you're going to go to this corner over here.    Patchwork Policy.    Patchwork Policy over there in that corner over there.    In Don't leave the room yet, okay?    Don't leave the room yet.    Ready to formalize.    Who would like to help?    Ready to formalize.    There we go.    Ready to formalize in the back of Chelsea over there.    In the back corner over there?    All right.    And can you hand this back?    And then the last one, post-crisis.    If you have not yet, we're going to be right in the middle.-crisis in the middle.    Right in the middle, okay?    Now, your job, you have 15 minutes, and I'll start the timer as soon as we stop, to put together an implementation policy.    So your task is to develop a 90-day AI adoption policy addressing four aspects.    Number one, what are the immediate actions?    What are the first two to three concrete steps this organization needs to take?    Okay?    Next, what is the policy approach?    Given this organization's culture and current state, what policy approach makes sense?    Number three, what is your training and learning plan?    And number four, what is your sustainability strategy?    Once you get to the end of these 90 days, how is AI?    I'm to continue to adopt and change your organization.    You have 15 minutes to, as a team, develop this plan, and you will need to assign somebody to deliver a two-minute report on what your answer to those four questions are for that organization.    Anybody not understand the instructions or need additional help?    One more time.    One more time.    Okay.    You have 15 minutes.    You are making, you are answering the four questions that are on your sheet, and you are electing one of your representatives to deliver a two-minute presentation of what is the answers to those four questions.    I will time you.    So try to keep it to two minutes.    What is your strategy for this organization?    Okay?    All right.    And I will introduce the organization before you deliver your thing.    So I will describe it.    You don't have to do that as part of your presentation.    That has to be part of your two minutes.    Okay?    All right?    If anyone needs more...    Handouts.    have a couple of more.    I have two post-crisis here, if you need more of those.    Post-crisis, here we go.    Josh, what are our expectations of any artificial intelligence that's not allowed?    Oh, my God.    Great question from Arianna.    Arianna, say that out loud again.    It's worth asking.    I'm asking a go-to.    Okay, wait.    All right.    Arianna asks, are there any constraints or limitations to what we are?    Are we allowed to use AI to help us with these four questions?    The answer is, because I love Taskmaster, if it's not in the rules, it's not in the rules.    We didn't forbid it.    It's not forbidden.    Good question.    All right.    Good luck, everybody.    You've got 15 minutes.    I'm to put the timer up on the board.    I'm going to do a call.    All right, raise your hand.    We're happy to come around and help if you want help.    We're happy to take a picture of it, so we need to take a picture of it on a virtual camera, just kind of try it out of the emergency gear.    Oh\!    Oh\!    Yeah.    Yeah, they're all the allowed to put the address of the plushies.    Okay.    In my hand, do plushies?    Do you know plushies?    Thank you, guys.    And not only do you know chess players, you know what I mean?    like they're positioning.    How are you, I don't I don't know.    don't know.    I don't know.    don't I don't know.    Fathom, Fathom, Fathom, Fathom.    Fathom, Fathom, Fathom, Fathom, Fathom.    Thank you.    Thank you.    So that's the way we actually need it.    What?    I'm sorry.    policy approach, how you implement it in a partnership between IT and science, and then basically, the next 30 seconds, we'll talk about training and learning plan, about how to actually put that implementation into it.    So, what if their policy approach is, if you're a section of practice, and ownership could be shared with the IT, one by 12 different leaders, would have received a date of the enforcement policy.    Thank you.    Thank you.    Thank you.    you.    Before I ask this question, this is short of how it's designed to be built on this.    Oh, no, it's quick.    Now it's working.    Okay.    No, no, no.    watch that.    For a second, it was like, this is fine.    For a second, it was work out.    It was, it wasn't, it was retreated.    It was, it was, retreated.    Because staff reactions vary.    Y got about eight minutes left.    that right?    No matter.    All this.    staff reactions vary.    I'm just saying it.    I know.    I'm we have to go see now.    Y'all got about eight minutes left.    You're all right?    Yeah.    Yeah.    Yeah.    Yeah.    Yeah.    Yeah.    Yeah.    Yeah.    Yeah.    Yeah.    Yeah.    Yeah.    Yeah.    Yeah.    Yeah.    Yeah.    Yeah.    Yeah.    Okay.    Animated Webinar.    Yeah.    Right.    Okay.    Yeah.    Yeah.    Okay.    Okay.    Yeah.    Pretty much what I got.    It's a great American committee.    Yeah.    Yeah.    All right.    All right.    And I don't think, again, it's a different thing now, or, you know, I could also, like, take on some of the things, you Oh, yeah.    Like, if it's a secure route.    Yeah.    Yeah.    Um, and then resources.    So, that of creates...    Thank you.    Thank you.    And even for...    ...    ...    ...    ...    ...    ...    ...    ...    It will only be one of your time.    I'll take more presentations.    So Exactly.    You're a bunch of But now that I've been through this I can work more I can Should I say Should I tell you 10 or Where you go Yeah Yeah    Thank you.    Three-minute-ish warning.    Okay, three-minute-ish warning.    Three-minute-ish-minute-ish warning.    I think that's a big difference.    That is what is the good and cold time that they were talking?    Mm-hmm.    So, right now, what about this is .    .    So, it did break down .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    Fathom, Fathom, Fathom, Fathom, Fathom, Fathom, Fathom, Fathom,    Our company has the amazing, honestly, gave us a different idea.    much of the team has come back.    Oh, yeah, they do trainings at me.    Yeah.    like, if you don't have to, like, jump on, that's pretty good.    Yeah.    The answer is, what are the first two or three things that I always make?    I mean, it's an athlete.    So if you were to make it the same thing, it's like training, interview, intervention, and supervise the doctor at the company.    That right?    Because I keep it three times.    What's the question?    think service is my only I question.    the portion that I think of.    Please send me on the So what's the address?    So what's the thing is?    What's the time we go off?    I service is only question.    What's the we Yeah.    That good.    I was recommending the department.    That will be close.    I'm just going to try to slide.    Time\!    All right, everybody.    Elect your speaker.    Elect your presenter.    I mean, you can all talk.    That's fine.    Tim, what was it called?    where did Tim go?    That's the right idea.    There we go.    I mean, can keep going to the end of the year.    you.    Thank you.    All right.    I guess people want to stay in their groups.    guess that's fine.    All right.    We'll all stay in our groups.    All right.    Where's my Wild West at?    That's you guys?    Okay.    By the way, as a true aside, has anyone here ever watched the video Norman Doors?    Has anyone ever heard of a Norman Doors?    Oh.    Okay.    So I have a quick thing.    You're all going to really appreciate this.    On your break or at some other time, go look up a, I'll share the video called Norman Doors, okay?    And it's about what are called Dumb Doors.    This is a great example of a dumb door.    And basically the premise is that when you walk up to a door and do the wrong thing, it's not your fault, it's the designer door's fault.    Because why haven't you?    handle on this side to pull, you should just get laid.    And why have the same exact design on both sides of the door when they do exactly the opposite thing?    It's a terrible, terrible design.    Okay, if you like the visual aesthetics.    Well, I guess maybe it's an aesthetics versus function.    It is a design.    All right, so Wild West.    So the current state of the organization is a mid-sized workforce development program serving justice-involved individuals.    Current state of AI, no policy exists.    About 60% of the staff, we think, are using Chats, VT, Cloud, or other AI tools independently.    Practices are totally inconsistent.    Some people are sharing client data, others are being cautious.    Staff have found AI helpful, but no one is coordinating or reviewing use.    The executive director is aware that AI is being used but has not prioritized policy development.    A funder recently asked about AI governments during a site visit.    and some urgency.    Key challenges.    Staff have already developed habits and workflows that may not align with responsible AI use, need to formalize practices, limited leadership bandwidth, staff may resist new restrictions because they've been operating in an unrestricted environment, concerns about being too late to establish guardrails, varying levels of AI literacy, and responsible use cases.    All right, Wild West, are you ready?    I'm going to set the timer.    You know, we're trying to be real creative with it.    Can you go to one more person for us?    I'm sorry.    We have to go first.    All right, I'll be honest with you.    were trying to throw that need a little more time.    All right, all right.    Well, let's see.    Let's see if one of the other groups wants to be kind.    Are our lockdown people ready?    Yeah.    You're ready?    Lockdown.    You all need to give lockdown a big note of thanks and say, thank you, lockdown.    We appreciate you.    All right.    Lockdown.    Is it helpful for me to read it or you guys just    Do me to leave it up here and let you all read it?    Or do you want me to read it out loud?    Oh, you can read that.    I'll give a quick synopsis.    You can give the context.    We're doing our two-minute pitch, and that's it.    All right.    behind us.    Okay, here we So, lie down.    Small program serving opportunity youth disconnected from school and work.    Current state.    Leadership issued a blanket prohibition on all AI tools after reading articles about bias in hiring and the ruggins.    Staff are frustrated.    They see peers at other organizations benefiting while they're blocked.    I think we talked about this.    No one on the staff has deep AI knowledge or expertise, including leadership.    IT department blocks access to most AI platforms.    Young staff members are using AI on personal devices anyway for work tasks.    Never heard of that before.    Growing tension between staff innovation and leadership.    Caution.    Key challenges.    Fear-based decision-making.    Staff leadership trust gap is widening.    Lack of AI literacy.    Risk of underground shadow AI happening without any oversight or safety.    Staff leadership doesn't stack.    Staff feel that leadership doesn't trust their judgment.    Leadership is genuinely concerned about harm to vulnerable youth participants.    In small team, it means limited capacity for executive training or policy development.    All right, here we go with a two-minute timer.    Are you ready?    Oh, wait.    Go\!    Our organization is at a crossroads with AI.    Staff are frustrated, leadership is cautious, and everyone shares a deep concern.    Protect and argue.    Our 90-day plan directly addresses these tensions through a human-centered organizational change management approach that builds trust, confidence, and safety step-by-step.    We start with a two-week appreciative inquiry discovery phase where staff share their hopes, fears, and experiences, including whether they can use AI personally.    This nonjudgmental process helps us understand hesitancy, services strengths, and establishes psychological safety.    Next, we create Peer-Buddy pairs so these less comfortable are supported by those more.    Every Friday becomes an innovation hour, a low-stakes space for staff to explore AI tools together over the 90 days.    We'll try multiple tools like ChatGBT, Co-Pilot, or Gemini, while using these simple scorecards to track emotional comfort, workflow, impact, and alignment with youth safety.    This builds buy-in by ensuring staff are not passive recipients of change, but active decision makers.    By Weeks 9 and 10, the team participates directly in selecting the AI tool we will adopt.    Leadership will make the final call, but the recommendation comes from staff, ensuring true ownership of the solution.    Using the insights from discovery and exploration, we co-create a cohesive safety-first AI policy, including exclusive guardrails to prevent harm to students, clear prohibited uses, and transparent guidelines for safety experimentation.    This safety isn't written for staff, it's written with staff.    Once the tool is selected, we deliver training tailored to that specific platform, focused on real workflows, drafting emails.    Summarizing Reports, Brainstorming Curriculum, Never Youth Data, Training, Incuse, Office Fours, Tool Demos, and Peer Modeling to Reinforce Ability and Confidence, Ability to Sustain.    All right, at the end, in short, this is financial change management, collaborative decision-making, cohesive policy design, practical training, and ongoing support.    transforms career into confidence and ensures we are able to adopt AI in a safe way for our youth and empowering our staff.    Yes.    All right, two quick follow-up questions.    Anyone on your team can answer them.    Answer them concisely, though, please, so we can keep moving on.    What was the hardest aspect of that policy, and what, if any, takeaways would you have for yourself, for your organization?    So, first question, what was the hardest part of that policy of making, if any of it, or was it all these?    Like,-making, like, what- Difficult decisions, or like, I don't know how to solve this problem.    We don't know how to address-    What's that challenge?    Oh, do you teach in the thing?    We took a picture of it, and we uploaded it, and we said, solve this problem.    And then we just said, hey, these are some things as humans that we know to be true, and that includes those.    Like, humans don't like change, so use change management, and be human-centered, and consider the children.    And then it wasn't that hard.    But I would change a lot about the thing.    15 minutes is not enough.    Understood.    Can I say one quick thing?    You mentioned something interesting.    I learned this, and this sounds familiar to you.    People aren't afraid of change.    You know what they're afraid of?    Lost.    And that's what comes out of the change.    We learned that in a leadership community that we try with pilots.    So when you think about people being afraid of change, think about what they're afraid they're going to lose.    It's like change is like grief.    think you're starting to go.    Yeah.    All right.    Thank you all.    That was fantastic.    All right.    Yes.    Yeah, takeaway for yourself.    We were able to discuss and figure out that a couple of us work with the same demographic, that the problem, and we were experiencing those challenges.    So I feel like these are takeaways that I can bring back to my organization and say, hey, we have a little bit of a plan to address that.    A starting point.    Awesome.    Thank you.    Awesome.    All right.    so much.    Wild West, you ready?    All right.    Wild West.    And go.    All right.    So our 90-day strategy focuses on bringing clarity, safety, and consistency without shutting down the innovation that staff have already embraced, right?    So in the first 30 days, we start with a post check and a full audit to understand exactly how AI is being used across the organization.    This gives us a real baseline which tools people use, what tasks they support, and whether the policy risks are they taking or if they exist.    At the same time, we introduce a gentle pause, right?    Not a ban, but a temporary hold on using AI for anything involving clients.    This allows us to keep things safe while we build guardrails.    also deliver quick foundational training on responsible AI privacy and ethics so everyone understands the why behind upcoming changes.    Next, we focus on policy.    Understanding from starting from scratch, we review the similar organizations are doing and adapt those approaches to fit our culture.    The policy would be permissive, but clearly defined, laying out what's allowed, what's prohibited, which tools are being approved, and how staff could safely experiment.    The insights from our artists help us identify AI tools that can be used organization-wide and eliminate risky and inconsistent practices.    Trainings and learning plans centers around people.    We begin with leadership buy-in, their movements, a peer-to-peer training, and then a trainer-to-trader model.    We host headquarters of learning sessions, build interactive materials, including an internal notebook element podcast, who failed me today, and developing all the workshops that meets staff with.    They are.    This approach reduces resistance, builds confidence, and creates internal champions who support ongoing learnings.    Perfect.    Finally, our sustainability plan ensures AI doesn't become a one-time project.    We designate an AI governance owner, set quarterly policy reviews, maintain updated approved tools, and keep training alive through refreshers and monthly shareouts.    This structure allows us to stay current, responsible, and align with funders' expectations while still supporting innovations.    In this short 90-day strategy, helps us move the Wild West to a safe, thoughtful, and empowering approach to AI, one that protects our clients, supports our staff, and strengthens our mission.    Ooh.    You made it like the God Bless America music coming behind that.    Awesome.    By the way, groups, if you could please email me or post into the announcements, whatever is easier for you, your report that you generated for this, and give me the subject of the email.    which group you were, the name of your group, and then we're going to make a little something for you during the lunch break, okay?    So if everyone can do that after you finish, you're welcome to make modifications to it, but before we get to lunch, just email me whatever your plan was, along with the subject line being the name of your organization, okay?    So our next one, who is number three?    Patchwork, all right, so let's read Patchwork real quick.    Where are my Patchwork people at?    Right here, okay.    is a large, multi-service organization with workforce development as one program area among many.    All right, current state of AI, organizational IT-approved, Microsoft Copilot-only, the lockdown advanced features like agents and deep research, which frustrates staff.    Some departments ignore the policy entirely, use other tools anyway.    Workforce development team wants to use Chattoot and Gemini for resume review.    A few workforce development staff use Chattoot and Gemini on their own time.    Current policy was written, this is literally from our life, 18 months ago.    We have two clients we're working with now that have exactly this problem.    18-month-old AI policies.    policies and haven't been reviewed or updated since.    One of the organizations we're working with, they, the WCISO Workforce Development Arts, like their policy was written in such a way that like their whole organization was in violation of it because Chachamichi just updated and it called out the model they were supposed to be using, which wasn't even available anymore.    And I was like, come on, guys.    All right.    No training was provided.    Different interpretations of the policy across departments.    All right.    I won't read all the key challenges.    And ask, I realize I'm putting you on the spot.    I know the timer creates this like race against time.    I would much rather hear a kind of summary of what your plan is doing and addressing than reading as fast as you can through the whole thing.    So if you can adjust it, that's better or less than you want.    This is why we go first.    I didn't know that until I saw it happen twice.    It's feedback.    Always iterating.    That is completely my fault in the design of the exercise, not yours.    It's getting very, we're AI.    For any Shark Tank people, this is something to think about, right?    The two minutes is about to race against the clock, okay?    It's a get weekend.    All right, go ahead.    So we sort of divided that way.    Some of us were human and talking, and some people were going towards the AI to solve this.    So the first question is, first two to three concrete steps.    We had the same feeling about surveying our people, our employees, and breaking it down into the departments.    We sort of put it to the department to get a sense of who's doing what, what's working, what's problematic.    And then the next department.    Let's report that back to leadership, and then we gather the different departments together to get a sense of, you know, the balance between the departments and what they each think, what their needs are, and what's at risk with the way things are going.    What's about my department, the policy approach?    That's me.    So given this organization's current culture and state, we believe that a more restrictive and more conservative policy approach, at least initially, is probably going to be what applies to the organization.    We believe that the IT department should partner with early adopters to find out what they're doing and really assess what the risks are, what's already happening, and sort of maybe even slow roll out a policy, you know, starting at the starting point, not being what the ending point will be, just rolling it out over the course of the years.    And we've figured out.    In order to do the training, want to start off by rolling it out with the people who are already into AI, sort of like what they said in the previous presentations, then the supervisors who can model that behavior.    They're going to be doing that by reviewing the AI usage with them and maybe have a reference sheet on what's allowed, what's not allowed, and give them constant guidance.    So there's going to be two-year, twice-a-year courses where all participants, all the people who are there going to attend and be able to catch up on what it is that the AI policy, since they're constantly changing, we're going to be able to give a – sorry.    No, no, no, no, said I don't want it to feel like a race against the clock.    We have to constrain for time because we have a lot of other people to guess here.    I'm sorry, that's my bad.    Oh, that's    All right.    was excellent.    That was excellent.    We got the gist of it.    Yeah.    All right.    And it's inherently sustainable, fam.    Thank you.    All right.    I'm doing better.    All right.    We'll get time.    So, Kim, do you want to read number four?    Okay.    Ready to formalize.    All right.    Established program serving immigrants and refugees in job training and placement.    Okay.    The current state is staff have been experimenting thoughtfully with AI tools for the past six months.    Informal buddy system exists where staff share tips and review each other's AI.    Leadership is supportive, wants to create an official policy to formalize good practices, strong organizational culture of learning.    Everything sounds good, right?    Good trust between staff and leadership.    However, okay.    The staff member who championed AI adoption and led the informal learning just now.    left for a new job three weeks ago, and remaining staff are committed but uncertain about the next steps.    So how do you translate these informal practices into a more formal policy that supports the culture?    I won't read all of them, but...    Are you ready?    Are you ready?    I'm here.    I feel so great to put you out there with me, okay?    Go for it.    All right.    All right.    Ready?    All right.    Hi, everyone.    Our strategy addresses the missing champion you heard a moment ago, risked by moving from this, like, single leader to then a structured team.    So the goal was to call this, like, a protected innovation.    The four parts are the immediate action from form a task force instead of this, like, lone ranger.    The second part was the policy.    So there's a concept of, like, having red lines and green zones, and I'll speak on that in a moment.    And third was to have a training.    So, like...    left for a new job three weeks ago, and remaining staff are committed but uncertain about the next steps.    So how do you translate these informal practices into a more formal policy that supports the culture?    I won't read all of them, but...    Are you ready?    Are you ready?    I'm here.    I feel so great to put you out there with me, okay?    Go for it.    All right.    All right.    Ready?    All right.    Hi, everyone.    Our strategy addresses the missing champion you heard a moment ago, risked by moving from this, like, single leader to then a structured team.    So the goal was to call this, like, a protected innovation.    The four parts are the immediate action from form a task force instead of this, like, lone ranger.    The second part was the policy.    So there's a concept of, like, having red lines and green zones, and I'll speak on that in a moment.    And third was to have a training.    So, like...    A bi-weekly rhythm to which the task force would be governed by.    And then when it came to sustainability, we thought of quarterly reviews.    So let's go back a moment.    The immediate action of the task force, the goal here was to stop relying on this informal buddy system and then have the AI task force include a staff, a supervisor, and then someone from the legal department.    When I spoke on the red line and the green zones, legal, the bright, the red lines, these are things that strict any, like, personally identifiable information because we are working with immigrants, so we want to be very careful with that.    And then the supervisor and staff would develop those, like, green zones, flexible guidelines that allow for creativity, and this keeps the organization safe without the culture being experimented on in a harmful way.    When it came to the trainings, right, we wanted to have the supervisor.    We lead that because that establishes some sort of buy-in and it's supported and it helps the employees kind of stay on track and keeps that practical aspect of it all.    Sustainability, we thought every like 30 days or so for the passports and legal to meet to update the policy and governance.    Are there any questions?    Wow.    Oh, great.    Thank you.    Thank you.    I have no questions.    thought that was going to be like that a lot.    All right.    Yeah.    Can we go again?    So you can give me 60 seconds.    All right.    We might give you a 60\.    Ariana.    Ariana, it's not a competition.    It's not.    However, in that set, they won.    No, of course.    No, of course.    Well, let's see how post-crisis does.    I feel like a lot of pressure now.    I don't know.    do.    All right.    Go ahead.    We it.    Post-crisis.    Midsize program serving New York City Housing Authority residents and public housing communities.    Okay.    Three months ago, a staff member accidentally uploaded client personally identifiable information, PII, into chat GPP, while drafting a case note.    Leadership issued an immediate temporary ban on AI tools while investigating this incident.    Staff are anxious and unclear about what's allowed or what will happen next.    The incident was reported to the funder as required.    Oh, they had to.    And the funder expressed concerns during the last quarterly report.    Leadership genuinely wants to move forward with AI but needs to rebuild trust first.    Both internally with staff and externally with funders in the community.    Some of the staff are afraid to experiment now, even with appropriate guardrails.    So these are a lot of trust stuff going on here and addressing a very real incident.    Okay.    So first we would like to, for our immediate action, would like to acknowledge the person and thank the person that did make the mistake for kind of opening everyone up to the, what am I trying to say?    Yeah, the reality of the tools.    And then we would like to start with the clear and calm reset.    Leadership sends out a quick message that doesn't point fingers.    Let's everyone know that something went wrong.    It's the systems and training and not one person that we're going to fix together.    Acknowledge that folks are nervous, pretending everything is fine is exactly what everyone's overthinking.    So we just want to acknowledge that everyone has some fear and we're going to try and get it under control.    Number two.    Yeah.    So for policy approach, we decided that.    We will create a structured policy ownership model where IT and compliance co-own development and maintenance of the AI policy.    All AI use will follow a strict privacy-first standard, meaning no client identifiable or sensitive data can ever be entered into external AI tools under any circumstances.    The policy will outline role-based permissions and an approval process, and we will also establish one centralized reporting and support channel.    Okay, and so for training and learning plan, our training approach is going to focus on clarity, confidence, and culture change, and that's going to start with a tiered training program.    So supervisors and people who use PII in a lot, high-risk roles, would get training that's appropriate for them.    It will cover what AI is safe versus unsafe, examples tied to our work with NYCHA residents.    And because some of the staff still feel anxious or burnt by the incident, training is going to include guided practice, non-punitive practice,    Q\&A, real examples, and we've all seen this with phishing, so just-in-time or micro-trainings intermittently because it's an ever-evolving thing.    And sustainability is going to involve three things, governance, updates, resources, so creating an AI committee, some points of contact that are going to review policy incidents and feedback on a regular basis, a refresh of the training since AI changes every time the wind blows, a refresh of the training and the policy review, and then a central hub with tools, guidelines, some materials and examples of safe use, just to rebuild that trust.    Awesome.    Thank you.    All right.    So, what-so, first of all, thank you, everybody.    That was fantastic.    So, I want to give, like, maybe just a couple of minutes for us to have a discussion about this.    If folks want to stay where you are, go back to your chairs, either way.    What will happen after this discussion, we're going to take a five-minute break.    People can go to the restroom, get your computers, because the next activity is going to be    The one at your computer activity today, all right, which is going to be using an interview prompt that we've made to help develop an AI policy for your organization.    So you want to be back with the people from your organization if you have other folks with you, and then that'll be the one thing for your computer today, okay?    But in terms of this activity, other than Ariana's feeling of gross unfairness and having to go first, you know, I just want to go again.    Go again, yeah, I think we should all do six seconds.    Yeah, did anyone have any major sort of questions, insights, takeaways, like anything that was particularly hard or challenging about that, or anything that was useful about it?    I'll go first.    Okay.    Yeah, go ahead, Allison.    I think from my team, we didn't talk about it, but it's kind of, we started brainstorming first because we had to plug it into AI first.    AI takes a while for like...    Generated, do all that.    while brainstorming, we started to think of all these ideas, and then AI kind of said the same things we already were saying, just in a more formulated way.    So it kind of reassured that we know what we're talking about.    I think we rely so much on AI that we think that, like, oh, we don't know.    But it's like, you do know.    you just brainstorm it yourself, it'll organize it better if the thought is there.    We have the thoughts that just didn't formulate it properly.    It was able to formulate it a little better than we can, but we have the thoughts in our brain.    So pretty much everything I came up with, we kind of already said.    It just organized it better for us.    Let me ask this question of the group, because I think Allison's on something really important.    Is there anyone, and Allison, you can answer this as well, that feels like, given a little bit more time, that you would have done a better job as a team if you were prohibited from using AI?    Or does everybody feel like your team...    see you    Plus AI does a better job than your team without AI.    Anyone feel like you would actually be better if you didn't use AI at all and just had more time as a team?    I think it's hard to gauge because we're all from different organizations, so we don't know each other, how we work, you know what I mean?    So it's not, we don't know what ideas would come from someone, so we're kind of taking that risk.    But I think by using AI and incorporating with the team, it's easier for people to also get ideas from the AI and kind of branch off of that as well.    So I'll up there.    I was going to say, because of the time constraint, think AI actually helped us to be able to organize our thoughts and get out and get the product out within the 15 minutes.    But with the group, like Allison said, we brainstormed first.    Everything the AI gave us a step back out to us, we discussed.    So let's say we had like half an hour, an hour, yeah, we could definitely do a policy thought.    Just to meet that time constraint, AI is going be the best.    Okay.    Yes, I am.    I think it's the order, which is what we talk a lot in our organization and the training.    We're going through performance reviews right now, and I put out, as a result of this training, partially, how to use AI responsibly for performance reviews.    Because we know people are going to use it, but it's basically like we've said, don't use it as the author, but you can use it as an editor.    So I do think that if we had done this activity, and then you have like 20 minutes, don't use AI, just like brainstorm right out your thoughts, then use AI, I do think the product would have been better.    Especially if we were part of the organization that this was, because we would have internal knowledge that the AI does not have as to certain words or certain ways to present it that would better fit with our audience.    So, yeah, I would want to, I would.    I'd to use AI, but I'd want to use it in that order.    Carlton?    I just want to piggyback off that.    think we would have presented better without AI, right?    And I'll say that because I present.    do association and stuff like that.    But I'm like, ooh, let me use notebook, you know?    And so I'm like, let me just rely on that real quick.    And then it was coming up with like four or five minutes, you know, videos, audios.    I'm like, that's not going to help right now.    And so I'm like, ah, .    You know, so, you know, so if, you know, the thought of like not AI, being there in the first place, I would have you know, Right, right.    What should we be looking for?    That can be a temptation to try to do something like cooler with AI, you know, that's better, but that doesn't actually meet the brief, you know, exactly.    But it feels so cool to do it.    Yeah, I've definitely fallen into that trap a lot, Carlton.    Yeah.    Yeah.    I feel like what helped break it down.    like, okay, I took a picture.    She obviously gave me like eight.    I was like, okay, make that a script, and now also add, like, what we had already extra thoughts on, in a sense, and then we talk about breaking it down further, all right, make a summarized pitch without losing any information in it, it took that and just kept, kept condensing into something more with the Richard and Richard, so it like, kind of like that, that conversation, right?    Yeah.    I think that's what, that's going to, like, the strong.    We're doing a lot of different context.    Did anyone go as far as to decide?    Describe the audience that you were going to have to present this, this plan, too.    Yeah, like we're presenting.    Yeah, and did, you talked about who the audience was for the presentation, great.    All right, fine, well, thank you, everybody.    All right, so, um, let's see, uh, we can do a break, I think, I sort of want to see if people want the break now, or if we're going into the AI policy workshop.    to to they want    People would like a break?    Yeah.    Thank you, Arianna.    Let's do a five.    We're going to do a quick break.    Okay.    Justin, do we have an ETA on lunch, by the way?    I'm going to look now.    It was supposed to be here around 11.45, but I haven't heard from them yet.    Okay, that's fine if it's a little later today.    It's fine.    You might have a working lunch today.    So let's do a 10-minute break.    Let's try to be...    Whoa.    Please sit there.    Disregard the fire alarm.    Okay.    Yeah, that'll be easy.    All right.    All right, so let's take 10 minutes right now.    Let's try to get back here at 11.55.    All right, everybody take 10, do what gotta do, and then we'll see you back here in 10 minutes.    And email me those plans, please, if you can.    Email or post it.    Or post it in announcements, yeah.    Like the summary pitch?    Yeah, the pitch that you made, yeah.    I don't know, I'll come.    Okay.    I'm going to put a bounty on the internet.    Okay.    Yeah, the thing is, know.    Oh, great.    Yeah.    Because we have a lot of them.    I thought you were just going to put money in the internet.    Oh.    Oh, great.    Okay.    Let's get into the last three.    Yeah.    All right, so I've got two out of the five.    just need three more.    All    Josh, it's in the works, so I'll see.    Okay.    Oh, yes, as as we come back.    Yeah.    Yeah.    Thank you.    you.    Fathom, Fathom, Fathom, Fathom, Fathom, Fathom, Fathom, Fathom, Fathom, Fathom, Fathom, Fathom, Fathom, Fathom, Fathom, Fathom, Fathom, Fathom, Fathom, Fathom, Fathom, Fathom, Fathom, Fathom, Fathom So, I think I heard that, and then, because he put the times in a little while, then I said, I'm trying to help you.    can't believe the most.    But he doesn't really like you out there.    I put it on my netbook.    If anybody's interested, they know you may get it directly.    Thank you.    All right, now it's on its way.    It's all right, it's all good.    Sorry if I have to pass it over.    I was just, I didn't want    I anything out loud, and I know you couldn't see all the hands behind you.    but I was trying to do the 3-1, let's wait for the people to speak before.    Oh, okay.    And I was kind of, no, no, I actually keep it here.    No, no, no, can't go on.    I'm I can go on.    I'm sorry.    I'm sorry, on.    You don't be repeating.    I didn't want to, you know, especially since you're sitting in front of me so I can do it privately, you know.    Oh, that's so sweet.    I don't get offended by people.    So let me know if she can, I can, well, wait a minute.    Also, if she, if can link in, okay, then at least reach out to me, and then we go.    All Wild Quest, I still need your, um, um, my lockdown group, I still need your plan.    All right.    see you soon.    Well done, well done, We'll right    And ready to formalize.    I still need your time, please.    you send him a message?    Got it.    So you send him message to the door.    That's nasty.    Yeah.    Yeah.    Carlton, thank you.    I mean, I think yesterday, who did I post it?    Carlton, have you checked out the slide decks and infographics that they just added the notebook allowance?    No.    You said that.    Insane.    That's funny.    That's funny.    That's That's Very is funny.    Really?    Oh, that's funny.    No, that's funny.    No, that's great.    Yeah, but, you know, the moment she I will connect her So they can chat Whatever Thank you So especially for We need to change that Because we need to actually make a living I keep doing the dumb door    Oh my son, he used to be like that, he's on one of the new cities, but then now he just, he doesn't have to be like that, he knows his thing, so now it's harder to get him to do something.    Okay, he's still, he's part of us.    When he was here, was he was he he we were really, he was working, which he was over for a lot of time, because, you know, we talking about someone, and we were just out there, getting an absolutely great, not just watching the, not even the case.    know, they're going to be out there, be out there, you know, were just outside, we sitting there, waiting, because if they do, we just do, they don't know.    They don't they don't know.    don't know.    know.    They They don't don't don't don't don't don't don't don't    I know, like Saka, yes.    But I still get a V-Shirt, yeah.    But it's like, oh my god.    then, he's got a big thing in his knees, and his grandfathers.    What's really good?    They keep playing together.    They keep playing away, so the chicks kind of die in the hour of me.    Or something I can't check out.    I know how to move up.    No, that's actually good.    They keep being like, really weird.    I don't know, okay.    I mean, I don't like that.    I don't know.    don't know.    I don't right here.    You see it.    don't No, I don't care.    I don't know.    care.    What we could tell you.    I don't we were really, it was what they've had.    I can just say, what they've I don't know.    Yeah, that's a good job.    We don't have these other scenarios.    Where the ropes are so dark.    Yeah, that's what I would do.    was all the way.    It was so funny because he told me that he'd take me.    The shirt was too small.    I can't play on YouTube.    Oh my god.    Yeah.    I'm to the moment.    Yes.    I can't play on YouTube.    I on just one video.    What's on IED?    I can't play on YouTube.    I can't on I can't play YouTube.    I can't on on Like, feel like thinking about that.    Then she comes and I ask.    So it's a good time to get some copy to this.    I take a five VCB.    Yeah.    It's like the two new t-shirts.    The champion of the setting.    The champion of the The champion of the world.    champion of The champion of the damn.    I think it only gives you five more characters.    Yeah.    You have a lot of different.    The of the The champion of the world.    And all of the studio things have the pattern.    Oh, so she works on the line.    I'm so she works don't want tell you about the point.    A position of the audience.    Yeah, yeah, tell the audience.    have been trying to like create, you know, like a whole list.    I've been trying to make a matter of a lot.    For many, it has to be like a few characters.    I'm just realizing it's like how many, how many, how many?    I haven't practiced that yet, but what the right path is, or like, strategy is.    Fathom, Fathom, Fathom, Fathom, Fathom.    Fathom, Fathom, Fathom, Fathom, Fathom, Fathom.    And this is wonderful.    I kind of want to slide it.    She's She's I'm She's like, come on, we're going to And I'm like, maybe this is And I'm like, oh, yes.    And I'm even using close-up.    And I'm like, I don't want to do it.    I'm good.    I'm going to grab it.    I'm to Of course.    I'm going to grab going to grab All right, everybody.    I got see her again.    see her again.    He's more of a relative.    No rivaling.    I got ready to pull the rise.    I'm going to grab it.    to    All right, I am only missing Lockdown.    Lockdown group, please send me your plan.    All right, you post it to the announcements in the community.    Por favor.    How much info do you need to start pitch by?    Whatever you want to send me is fine, you know, it's Can I just put it in your comments or send it to the announcements in The announcements is fine.    Okay.    thank you.    All right, sorry about that.    Oh, not at all.    Not at all.    All right.    I'll send you my other pitch.    I'll send you my I still feel a type of way, okay?    I still feel that I feel.    All right.    Wait, what's the, uh, flap one?    Can you do it once?    Three times.    You can once.    Yeah, you can do it once.    once.    times.    Wow.    Um, got a good three.    All right, so now to the policy.    So just out of curiosity, um, how many of your organizations do have an AI policy?    It's a secret one.    Yeah, secret.    The secret policy.    was yet another organization.    Okay, so not the majority.    Am I safe to say not the majority?    All right.    So one of the things that we want you to be able to go back to your organizations with is, I'll say a policy, right?    But a policy-making process that you can kind of take back with you, and do with state.    stakeholders at your organization.    It is important, as we heard in each of these scenarios, they got different stakeholders working together, right?    The ones we just heard.    It was either IT and the staff, the folks who had been real innovators, and, you know, so you need your stakeholders.    So not everyone is in the room from your organization to do this, but this process that we're going to go through is going to kind of take you through the types of questions that you want to ask.    Or that you'll want to answer as part of making a policy.    And you will also get some ideas about who you want to have in the room from just hearing this, okay?    But I'd say we're shocked.    We've been teaching AI for, you know, whatever, since 2022\.    All right, no one had a policy then.    But we're shocked, but we're still at the number of organizations that will speak and, like, lots of organizations and most    Most of them do not have a policy, okay?    And I'd say that's the biggest risk of all that organizations can take on is having no policy process to do this.    So what we have here is an interview prompt, okay?    And so this also will give you some experience using an interview prompt, and this is a type of way of prompting and interacting with AI that is extremely helpful in certain kinds of use cases.    policymaking being one of them, all right?    So you can go to tinyurl.comai-policy-prompt, okay?    And that should take you to this.    You can go back to the flipping type in.    Can you just go back to what you think?    Okay.    All right.    So bring the policy.    policy up on your, probably easier to do on your laptop, though you could do it on your phone, but you'll want to paste in this long thing into the prompt.    Does everyone have it?    Hmm?    Yes?    Does anyone not have it?    Okay.    Okay.    So when you drop this prompt, and this is also in the community for you, there's actually a little article on it.    You can share anything in the community with your colleagues, by the way, who are not at this thing.    But, um, oops.    Oh, sorry, do you me to stay there?    Um, I'm on, uh, character limits.    Oh, the character limit.    I could make it 8,000 characters.    I could could it,000 this.    see    For Co-Pilot?    Yeah.    I'll make you a sub 8,000.    I've been last week.    Yeah.    Yeah.    Sometimes I just cut something off that I wouldn't know.    I'll it in the bottom of the same document.    All right.    Thanks.    Okay.    So has anyone not been able to get to the document?    I'm in the document.    Yeah.    Okay.    So then Josh is making for, so folks on Co-Pilot, you might have trouble because this one is a little longer, but if you're not on Co-Pilot, copy it and paste it into your chat tool of choice.    And this will guide you through a set of questions, right?    So if you get to a point where it's like, I'm tired of answering these questions.    Have I answered enough already?    You can say DRAFT NOW.    Okay.    In all caps.    And it will go ahead.    that process.    I a like    and make the policy, but the more you get to interact with it, the more it will reflect your needs.    Okay?    So people are staring intently at their computers.    Have you all started?    Are you in it?    Okay, you're doing it?    Okay.    It'll be interesting to see from those organizations that have more than one person, which is all of you, I think.    Thanks, Jeff.    You're welcome.    You see it?    Yep.    When you each do, when you do different policies to then compare yours later on after this.    Okay?    So this walks through building an AI acceptable use policy.    It would be interesting, Meera, to see, like you said, you already have a policy at your organization?    No, I'm skipping it.    Somebody else, I'm not sure.    I don't even know if we have a policy.    Oh, okay.    Somehow I thought, someone has a policy that, okay, not many.    Okay, for some reason I thought, oh no, you have lockdown.    But you have lockdown, but no policy.    Oh, right.    Usually lockdowns have policies.    But the, so it'll be interesting to see for those organizations that have policies, what you produce, especially if that policy was written to your, okay?    If anyone has any questions about, questions, caller.    So I'm just going through it.    If you want to watch on the screen, I'll just be doing it for Goats of Anarchy.    Did we do Goats of Anarchy with this group?    You guys have heard of Goats of Anarchy before?    we used that?    In this class, it was a different time.    For real, non-profit.    Oh, we used to put the trust.    Oh, it trust.    That's right, that's right.    I know a lot of other ones.    What is that point here?    We just completed your activity with what it does before, such as development.    please.    let's hear.    And the first case, I don't know what the activity was, and what they did in response to it, and so that's it.    Yeah, if you want a few, but you can say check.    Thank you.    Please create an infographic provides an impact on organizational students who teach AI adopters.    Anyone needs help or is running into any issues, raise your hand, let us know.    We're happy to help you out.    Any of the questions, like stumpers?    And when you're doing these interview-style prompts, like, you have no fear to say, I don't like that question, ask a different one.    Remember, ask me one question at a time, please.    Please skip this question, you know, whatever makes sense.    I'm going to go help Justin set up food.    When you are done with your policy, don't rush.    Come out and grab lunch.    We'll have lunch, and then we're going to start the Shark Tank right around, maybe 12.30?    Yeah, time is it now?    Yeah, around 12.30.    Not that an AI policy stands between you and lunch, but that would be the case, just to point that out.    No lunch for you until you finish your policy.    lunch for No lunch for lunch for for you.    No No lunch you.    No lunch you.    No lunch for for you.    No lunch for No No lunch for you.    No lunch No lunch you.    you.    Yeah, and then I'll share that afterwards.    All right, if want to go help Justin set up, and you want to stay here and...    I'll be, I'll be, yep.    Thank    Thank you.    Thank you.    You could, no, if you feel like, hey, I've answered like enough of these kind of questions, you can get them.    because this is, yeah, yeah, I need to take a look.    Yeah.    says we're to, we're being but, we'll be, we'll be.    It's terrifying.    It's so sorry.    It's It's scary.    Yeah.    Yeah.    Yeah.    Okay, thank you.    All right.    Thank you.    Just to meet you.    Can you meet Yes.    That's    Our mission, our vision, our passion, commitment, board leadership, learning, and response.    If anyone's stuck in a phase and you're like, we've answered these questions enough already, you can say, please move on.    It's very accommodating.    Thank you.    Thank you.    How many faces are there?    I can't remember, it says on the, oh, on the three, okay, We did it.    Bye.    Okay, all right.    Thank you.    Thank you.    Thank you.    Fathomâm, F2, and Fathomâm, CES.    Fathomâm, CES.    Fathomâm, CES.    Fathomâm, I don't know.    Thank you.    I can tell you guys what gets covered in the different phases.    that be helpful?    Sure.    Okay, so phase one is the organizational context.    Phase two is your current state, like what's happening now.    Phase three is risks and concerns.    That could keep you there for a while, probably.    Phase four is governance and enforcement.    Phase five, training and culture.    And phase six, specific considerations.    Phase seven is the easiest, it's kind of what output do you want, word or PDF.    Thank you.    When you actually sit down with someone at your organization, you want to spend about an hour, right?    And you will have prepared them with some of these types of questions.    Thank you.    Thank you.    Thank you.    Thank you.    Thank you.    Yeah, we're gonna have to get them through.    My God, no one's like, you know, no one's like jumping for lunch.    It's, it's, a long, it's a long view.    .    See, that's it.    Oh, where am I talking to the same thing?    Okay.    Ooh, here we go.    It's just one of the...    I mean, they have come from, like...    This is a palace.    That's pretty cool, though.    That's why they will kill me.    creating my company's palace.    All these big shots.    Who are you?    They will talk to me like that.    They will do it.    You must I will see.    Fathom, if I send them now, I'll so, on Friday.    All right, Carlton?    Yeah.    Oh, everybody can look at this, let's see.    All right, let's see how it looks.    All right, here we go.    All right, so those of you who are notebook.lm users, who's a slide deck function, as well as an infographic.    Yes.    All    Yesterday, Tim introduced me to it this morning, so this is our activity that we did.    Forging the future, reflection on your AI adoption playbooks, your mission from blank page to action plan in 15 minutes.    Five organizations, five realities.    Playbook for the Wild West, protect, don't punish.    Playbook for Lockdown, build trust at a human pace.    Confusion to cohesion.    God, this is nuts.    That's crazy.    It looks better than the MAI.    It really looks good.    It looks better than the slides that I spent like hours on.    Yeah, no, wait, and then we're not done yet.    They also make infographics, let me pull up the infographic here, go to notebook.lm, close that, and here's the infographic, let's get a look at this, and let me see what you're sharing that.    That's crazy.    That's nuts.    So that's for the Google Workspace folks, that's notebook.lm, they just added that yesterday or the day before.    So all I did, all I did, okay, was, that's why I asked you all to send me these things, right?    Let me get my right screen share on here.    Let's do the whole desktop so we all see it.    it.    Let's do    Okay, let me pull that, was go into Notebook.    I created Google Docs out of the ones that you made.    I took that document, that one that had just all the strategies, the different organizations, the profiles in it, and then I grabbed the five slides that set up the activity and just made those their own slide deck and then just added that.    That's all I did, just added those into the Notebook and then just basically clicked Slide Deck, and I did a little miniature prompt to say what it was for.    But not a whole lot of customization.    So you made, you, did you do in a separate Notebook then the AI adoption planning and make that slide first so it didn't pull in?    Yeah, I went to the slide deck and just selected these five and made them their own slide deck.    So it only had that activity because I thought if I put the whole slide deck in, it would pull stuff other things in the slide deck that I didn't want for that.    I wanted to focus just on this exercise and the outputs of exercise.    So I just copied those five slides.    So    And these were slides you already have?    We already have it.    These are the ones we showed you, yeah, for the activity.    And so I just put those into the notebook and then asked for those slides.    Not bad.    I like that notebook element.    It's like kind of like, I like it.    Yeah, no, it's a neat tool.    work you've already done in a sense.    It's not...    All right, we'll share all this stuff in the community and in the session before we wrap up, But thank you all.    All right, so we're obviously not going to do Shark Tank at 1230\.    But we do, I do want to leave ourselves a lot of time because we need the Shark Tank.    And then we also need to kind of wrap up and conclude our session.    So let's try to get food and be ready to shark at 1245\.    Our sharks, you're going to be sitting up front facing that way.    I'm going to rearrange a little bit.    who you are.    So it's okay if you're eating while you're Shark Tanking, that's fine.    YoundormaleDA.    you.    Yeah, and in case you don't know who you are, Carlton, Ikea, Ariana, and, you know, there you are, okay, and then did we recruit a fifth one?    We did not recruit a fifth one.    You mentioned you wanted to be a shark in the email, right?    Yeah.    You want to be a shark?    Yeah.    You are our fifth shark, and Darlie will be our fifth shark, okay?    And you can still pitch, you just can't shark your own pitch.    That makes sense.    The safety check.    It's a personal safety check.    That's what my grandma always told me, anyway.    Who's pitching again, The pitch is...    Hang on a sec, and I will tell you.    Make update, Darlie.    There we are.    Okay, so these are...    Presenters.    We're going to go in order.    By the way, Consortium for Work, who are the first two?    These were the first two, Justin, that volunteered?    Yes.    Okay.    Yeah, the first two, sorry, I'll tell you, I think it was CWA and Good Shepherd.    Is that what I told you in the email?    I can bet.    I owe you gift cards, so you just need to tell me.    organizations, I'll tell you who.    Okay.    Do you have to send you the slide deck?    No.    Oh, yeah, yeah.    If you could put it in the community or email it to me, then I could put it up on the screen for you, yes.    Unless you'd rather control it yourself, we can enable the AI, the Zoom, the screen share.    But it's easier if I drive and put it up there.    You could have my laptop to do it while we're doing it.    That's fine.    Yeah.    Wait, I...    So you can send it to...    Oh, no.    Small Business Services and Good Shepherd were the first two.    have any    Small Business Services and Good Shepherd, okay.    So can we reorder them for a small business?    They're going to go, and who is first?    The first one, think, yeah, so if just do those two.    Oh, all right.    In any order, yeah.    As as those two are on the top.    Good Shepherd is small.    I'm going to go get some food.    And it was all right in here, and now it's cold.    Yeah, it's freezing in here.    Yeah.    Yeah, it's pretty cool.    I feel like the H2 has on, not T-E.    Take on and put on your clothes.    Yeah, I keep taking on, take on.    I got hot flashes or something.    I'm saying your name right.    is Zikaia, I'm saying it Oh, it's Zikaia.    Zikaia, okay.    No problem.    The attempt is better than what my grandmother had.    That is a big swing of the business.    You know, I'm just stuck in the waves.    Like that's your name.    Okay.    You're the only one calls you.    What's the expression?    like your certain hands were out of front.    Oh, that's the good one.    Donate me left.    That's a boy name.    Oh, that's so sweet.    I hope it's a good story.    That's so sweet.    There's a lady that is in there.    She is just like, my name is Shannon.    She told me today.    Today.    That's like my sister.    has her best friend called her Zenaya.    My sister's name is Zenit.    Like, okay.    My mom's name is Naomi and all of her friends from like way back when they call her Naomi.    Everyone always calls her that.    You know.    Or not.    And she listens.    Yeah.    Yeah.    She's used to it.    Yeah.    Yeah.    Yeah.    I'm trying to correct you.    Bazel, people call him Bazel, and he always had to correct you, and you always had to correct him.    I think people would just stop correcting me, but I found myself calling people a name, they're like, they're not by name.    Is it not you?    It's like, oh, you should.    was like, I want to get it right.    When I was younger, would just say, people are like, oh, Zakiya, I'm like, yeah, Zakiya.    Because our people know Zakiya, and that's a weird thing.    Exactly.    now, I'm like, no, I'm to decide you people.    Once I go to college, I'm like, I think it's a differentiator, you know, from other people.    And again, it's important to people when you want to.    Exactly.    That's your name.    It's respect that, yeah.    It's the band.    My son, it took me a long time to select his name.    finally have- There's this door on the 10th floor of the Vox Media Office that I hate so much.    God damn it.    Thank you.    We're okay.    You ever get this door on?    Me too, Kelsey.    But here's the thing.    As soon as you start looking for confusing doors, they are everywhere.    It's push.    Why?    I feel like Roman Mars would know about this.    This is 99% invisible.    And those doors you hate are called Norman doors.    Um, what's a Norman door?    Don Norman wrote the essential book about design.    He is the Norman of the Norman door.    All right, and where is this guy?    You must go to San Diego.    Okay.    Hi, Joe.    Hey, I'm Don Norman.    I'm...    Gee, you know, it's hard to describe what I am.    Well, he's been a professor of psychology, professor of cognitive science, professor of computer science, a vice president of advanced technology at Apple, but for our purposes.    I was spending a year in England, and I got so frustrated with my inability to use the light switches and the water taps and the doors, even, that I wrote this If I continually get a door wrong, is it my fault?    No.    In fact, if you continually get it wrong, it's a good, and if other people continue to get it wrong, it's good sign that it's a really bad door.    A Norman door is one where the design tells you to do the opposite of what you're actually supposed to do, or gives the wrong signal and needs a sign to correct it.    Why does it need an instruction rule?    That is, why do have to have a sign that says push or pull?    Why not make it obvious?    It can be obvious, if it's designed right.    There are a couple of really simple, basic principles of design.    One of them I'll call discoverability.    When I look at something, I should be able to discover what operation...    The principle applies to a whole lot more than doors.    It's amazing with many of our computer systems today.    You look at it, there's no way of knowing what's possible.    Should I tap it once or twice or even triple tap?    So discoverability, when it's not there, well, you don't know how to use something.    Another is feedback.    And so many times there's no feedback.    You have no idea what happened or why it happened.    And these principles form the basis of how designers and engineers work today, commonly known as user or human-centered design.    I decided at one point the word user was a bit degrading.    Why not call people people?    And it's amazingly simple and amazingly seldom practice.    We call it iterative because it goes around in a circle.    We go out and we observe what is happening today.    We observe people doing the task.    And from that we say, oh, we have some ideas.    Here's what we should perhaps propose to do.    And you prototype your solution and test it.    Quite often these are wrong at first, but each time we go around the circle we do a better job of making advice until the point we're actually making something that really works.    And this process has spread all over the world.    And it turns out it's improving lives.    From better everyday things like the ones that Don wrote about.    To using the same process to solve huge problems in public health and developing countries.    Water.    Sanitation.    Farming.    Lots more.    So what would it be a better human-centered door?    An ideal door is one that as I walk up to it, as I walk through it, I'm not even aware that I'd open the door and shut it up.    So if had a door which had a flat plate, what could you do?    Nothing.    The only thing you could do is push.    So see, you wouldn't need a side.    A flat plate, you push.    This kind of push bar with the piece sticking out on one side works well too.    So you can see what side you're supposed to push on.    So you can see you're supposed you're supposed you're supposed to side to do.    what to you you can    But we still have terrible, terrible doors in the world.    So many of them.    are lots of things in life that are fairly standardized and therefore whether I buy this house or not is a better function of whether it has good doors in it.    So except for safety reasons, its doors tend not to work.    But the tyranny of bad doors must end.    I think that it's a really sh\*\*ty design.    In they put full handles when it's a push.    And that should be a flat panel right here.    And not a f\*\*king full handle.    That's why you're doing this.    It's very misleading.    You're right, Becky.    You're  right.    And if we all thought like you, well, we might just design a better world together.    It won't open because it's a security door.    I'm gonna hate this.    I have this much bigger beef, so...    What the f\*\*k do you do?    Hey, so as you can see, since I started making this...    Since changed the door a little bit, I guess it's a step in the right direction.    Thank you so much for watching, and to 99% Unphysical, one of my favorite podcasts, it was so much fun to collaborate with them.    Thank you, and check them out on any podcast app or 99pi.org.    Yes, now you'll see them everywhere.    Yes, they do.    They are everywhere.    What are you going to do anymore?    It's for you to get with me.    That's nice, yeah.    That sounds better than what other way to do.    In the bar.    We're doing a people on a cell.    We don't want to do that nice.    We're doing one side of a little.    On the other side.    that a thing where there was nonsense?    Everything.    Yeah, it's of simple.    Oh, yeah, if you back up, it's really great.    Yeah.    What's the plan, right?    Some major, right?    No.    Yeah, probably a high-waves-down.    Oh, it's It is the one more now.    Yeah, it's probably working.    No, I'm not touching anything, I'm just wondering what it's saying.    Right.    Yeah.    I can see them.    Bob wants to talk to you, if you want to be a part of that.    Yeah, probably did it, I'm good.    They probably even there, I know.    And they have to.    I know it's pretty strange.    do do?    Do you to live there like, I don't know if you.    Yeah, of course.    If you want to be a part of we can like send them out.    sorry, I'm the house, right?    I can send them out.    Well, you've got to send some vibes.    Yeah, you can do it.    No, we'll do it.    Yeah, yeah.    Yeah.    I'm sorry.    Can you just let me know anything?    Can you just let anything?    I will need help with these slides.    Oh.    But that's it.    I'm gonna just like please do this.    Mm-hmm.    That's what I'm gonna do.    You're right with it.-hmm.    I don't think it's famous.    Wait, what?    just like, what?    It just reminds me of the autonomy.    It's like, I don't know.    like, like, my back.    Well, definitely don't wanna do that first.    No, no.    You sit down.    I used to make new projects.    Me too.    Cause I was the one who would do the work.    Where it'd be like, hmm, you know.    It'd be like, But you could do that.    I didn't really thought about it.    So how was it?    I'm going to take now.    I did, I'm I'm gonna take I will tell you.    I don't know how this works.    You know, I'm very nice in you, because sometimes you see your little hair now.    dude, yes.    Sorry\!    Oh, you smile.    You too\!    You look like you might be that.    Yeah, yeah, yeah.    There you go.    That's the love of me for the speed.    Hope you didn't say that.    You know what he has?    You know what has?    No, no, no, no, no, I just did the dumb-dork live.    too.    Yeah.    No, I can't do that.    Crazy\!    They're usually...    Thank you.    Fathom, Fathom, Fathom, Fathom, Fathom, Fathom, Fathom.    Fathom, Fathom, Fathom, Fathom, Fathom.    Should I tell folks out there in like five minutes, minutes?    I think he wants to go to other founders.    Five minutes, five minutes, bring the food in, that's fine.    Well, I need to start setting up the Shark Table.    Oh, We can move some of these chairs.    Yeah, but I'm going to move back.    Can we put them over here?    We could move ourselves.    I was going to put them over there, where Allison is.    I've been hearing people walking back and forth.    Like dead center, or no?    Do you want to be in the middle?    People bumping in    I want to angle them in from the side, they need to see the slides as well.    Okay.    The only thing is, it's just so many ingredients.    Yeah.    It's so much to buy it.    The first time it's like, It's your dinner.    You're like, I could be eating like lobster, right?    I'm going to use this.    I thought it was too easy.    I'm going to use I'm going to use with the dog.    This one, the major?    The major?    The Yes.    major?    I'm crazy.    I'm crazy.    I'm crazy.    I I'm making my own predictions at home.    Because I'm thinking like New York sometimes.    New somewhere.    Yeah.    That's crazy.    I was going to say this.    I mean    I like that.    Wow.    Yeah, this is cool.    It's beautiful.    I'm But she can see on this.    I got it.    I got it.    I got this.    And you guys know.    I got it.    I do have those?    I don't know where they got me.    Don't go back.    I imagine it doesn't work.    I got to try those.    It doesn't work.    They're like, see my .    They don't work.    It would have had to have be the asset.    Have it on a website somewhere and then.    No.    No.    No.    No.    No.    No.    No.    No.    No.    No.    No.    No.    Thank you.    Thank you.    But you can't see the screen from there.    Okay, shirts\!    Shirts assemble\!    But where, what are they going to be looking at?    What are they going to be looking at?    Well, some of them will be able to see that.    It's very hard to see from over here, actually.    My laptop, I'll have it right here.    So, one of them, okay, there's five.    We could add one of those shares.    Um, yeah, well, no, no.    Okay.    So we could put one on the other side of the table.    Here.    Here.    Okay.    Okay.    Okay.    person would be able to see the screen.    They'll be able to see it.    right.    So, let's get our Shark Tank rules up.    You're going to yourself around this table here.    Shark?    out here.    Josh?    So, here are the sharks.    Oh, okay.    So, they get to this way.    They each get to that.    Can you let Ariana pass him?    Nope.    It's okay.    Okay.    Okay.    Come on.    Let me start pause away.    Here it is.    Short Causeway, that's good.    Thank you.    It's Ikea.    Ikea.    It's Ikea.    And then you each get these.    get your little cards.    Okay.    Your rating card.    Okay.    And if you can't see the slides, I'll have them up here for you.    okay now the presenters you need to share your slide decks of the announcements for me so i can put them up on the screen for you okay so make sure i can get to your presentation and a reminder so first of all let's meet our sharks all right so we have you know i'm not sure if i'm sitting last i got it great okay we have is that yeah mcleod your field mcleod mcleod there we go all right we have darlie corneal    I'm taking a picture of our panel of sharks.    And Ariana Baltimore, thank you to our wonderful sharks for agreeing to help us out today.    Now, here's how this is going to work.    And as you have all learned the hard way today, this will be timed.    right.    Yeah, I really think that was nice.    And I will play it off.    Yeah.    So you will present your pitch.    You'll have a – I'll let you introduce yourself before the timer goes on.    And then at some point, I'll say, when you're ready to begin your pitch, you'll get your timer.    And the person pitching go up to the front?    I would love it if they came up to the front.    I'll put your slides up on the screen as long as you share them with me.    And then you're going to talk from over there.    Yeah.    In fact, we could even – why don't we even – Give them a lecture?    Yeah.    Why not?    Why not?    Have it.    Mine is what you right?    All right.    Is this already in here?    Yeah.    I was like – Sorry.    Shark, you're going to be right here, you're going to present over there, and I'll have your slide go for it, okay?    Present tank.    Yeah, present to the sharks, all right?    Can I help?    I help?    Yeah.    Are we getting these for each of the presentations?    At the end of each presentation.    Just hold it I like the judges.    Gymnastics and the Olympics.    Don't keep the name of you.    Well, hang on, hang on.    So, you have two minutes to do your pitch.    The sharks have five minutes to ask questions.    We encourage you to be tough but fair.    Get clarification, pose challenges, be, you know, a little bit, not brutally adversarial, but be tough, okay?    And then, you'll have two minutes to give your final score.    So, after the five-minute question period, we'll start a two-minute timer.    you need to give your green light, slow ahead, or please stop.    Bye.    Bye.    Bye.    Thank    Okay.    right.    During the five-minute period, it's a conversation.    So they can ask questions and the presenter can give back.    Remember, keep it tight.    You only have five minutes.    And that is the format.    So it'll take about 10 minutes around.    We're going to see if we get through five of them.    And that's basically the plan.    Our presenters are New York Department of Small Services, Good Shepherd, Consortium for Worker Education, Co-op, and NYC Department of Aging.    And NYC Department of Small Business and Good Shepherd, you are our first two volunteers.    So I owe you $25 gift certificates each.    You just have to tell me how you want it.    So I will give you, if you give me an email address, I'll send it there.    If you, I can print it and email it to you, whatever you want.    Okay.    All right.    right.    So if you are Department of Small Business Services, are you ready to present?    We're ready.    We're missing a thing.    Not ready.    Okay.    Good Shepard Services ready to present.    As soon as we finish doing, all right.    Do I have your deck in the community?    Yep.    Excellent.    You win.    All right.    Announcements.    AI Literacy Pitch Deck.    Beautiful.    All right.    And I will hold this for the presenters here so you can see if you're in the room.    So many good models.    You're so brave.    So brave.    Brave or foolhardy, I'm not sure.    And Josh, are you going to turn the...    Yeah, you're going to say next slide or whatever you want, however you want to do it.    right.    do as best I can.    Thank you.    Let me see if I can get this up just a little bit.    I feel like I'm going to be standing in front of it, though.    This is good, right?    Right here.    You're at the lecture.    You're perfect.    Oh, I have to go on the lecture?    Oh.    You don't have to.    You're going to more engaged.    You're to be    Oh, wait.    I have a question.    You could just echo, but there's no microphone.    I'm not nervous.    Will I be able to see a timer?    I will have it here.    I can put it in front of you if you'd want.    That'd be great.    Okay.    Can I introduce myself before the pitch, or do I have to start, include the introduction into the video?    can do this in 15 seconds.    Oh, okay.    I'm good at that.    I've been ready.    You go.    And is it okay if I record?    Hi.    Yes.    Hi.    My name is Luann Blaubor.    I'm the Vice President of Vocational Programs at Good Shepherd Services.    Good Shepherd is a huge multi-service organization.    I oversee a department of nine distinct vocational programs.    These nine programs are all approaching...    AI literacy in silos, and so program leaders have different levels of competency and interest in AI.    we can go to the next one, Josh.    And this is creating, A, inconsistent adaptation, on the spectrum to no adaptation, and then meanwhile, we have 240 plus participants every year who are at risk of falling behind in an AI-driven job market.    So why does this matter, Josh, next one.    So AI drops into a pre-existing situation where communities, families, and individuals that we serve have been economically marginalized throughout history and were already being disadvantaged by the digital divide where computers were less likely to be in households.    And schooled in our communities.    And    So AI adoption is accelerating, and if we fail to act now, it'll deepen economic inequities, and participants will be excluded from an AI-driven workforce.    In addition, if we don't lead, our program's credibility suffer, and we stand to lose out on funding opportunities and forfeit our standing as employability experts in the sector.    So what is our solution, Josh?    So we propose a train-to-trainer AI literacy program for program leaders and participant-facing vocational program staff, two to three interactive workshops covering ethics, privacy, and the potential for hidden and not-so-hidden bias, as well as practical applications like resume tailoring and career mapping, plus a curated toolkit with templates and approved AI tools.    Next one, how we'll do it, the stakeholders we have to get on our side would be program leaders, participant-facing staff, IT, and executives.    Am I done already?    Yeah.    Just a minute, Grace.    Give you 20 seconds to wrap it up.    Okay, great.    Yes, I can do it.    Okay.    So the tools that we can use are co-pilot right now.    We're looking to get Gemini approved since most of our participants use Google Workspace.    Our vision of success is that six months from now, all the vocational program leaders will be confidently integrating AI and job readiness curricula.    Participants will use it for resumes, career mapping, and job search.    And this initiative is urgent, feasible, and transformative.    With your support, we can ensure our participants and our organizations thrive in the AI era.    goes fast.    Yep.    I don't think I'm done.    No, you're not done.    Now it's when it gets hard.    You've got to stay right there.    You've got stay You've to right there.    Ask a question.    Wonderful idea.    And actually, my program can actually relate to what you talk about.    So the question I have is, Amy, it's not an issue in your organization.    How do you get the buy-in from your staff?    Oh, from the staff.    So we, you know, I think like the, we can all agree that the bottom line is our participants and that our participants are going to be in the job market that we've already entered, right?    Like we're already here.    So it's, we're at a less critical juncture, right?    Our participants are at a way, far more critical juncture.    And I think we all know that our participants have already been left behind in so many ways, right?    And that this widening gap will only ensure that participants will be further behind.    So really by appealing to my staff's, you know, motivation and passion for their work.    Where is your staff currently when it comes to how they're using AI tools and how would you gauge them?    So I would say all over the map.    So we have people like Shanae who incorporated it into a resume development workshop to like great effect just recently.    And then I have some program leadership who are like, I will never touch AI.    So it's everything in between, but we're really slow and experimental, and my organization hasn't helped because the AI policy is not explicit.    It's there, but no one knows what it is.    I have a question.    You mentioned participant.    This seems to be tailored to participant mostly, the outcome of it.    You mentioned the digital device, but you didn't inform at all how are you planning on closing that digital device?    Participant will have outdated system, outdated equipment.    So how is all that being integrated?    Am I lacking?    Question is, I don't know what you are asking for.    Okay.    I don't either.    I thought it was zero dollars.    I just want you all to think it's a great idea.    So closing the digital divide is such a great question, and I think this is where we have an advantage.    Our participants do have phones.    AI is very useful on phones, not as useful in running a word program, right?    Phones weren't.    So this is our opportunity.    So I see this, for us, if we seize this moment, as an opportunity to have our participants, to allow our participants to partake in the same way that their counterparts across the city, and indeed across the country, are used.    You may have said this already.    What's the age range of your participants again?    Thank you.    We're actually about 15 through 29\.    So that's across nine programs.    That's a big range.    And have you done any type of, like, AI literacy with them?    Like, gauged where they are?    in terms of already using these tools?    Only in a very, like, local, personalized way.    Like, Sine, when she introduces it, we'll talk to the participants about what they've seen, but we don't have an organized approach to that yet.    Okay.    To that, as a follow-up, how are you planning to organize the data that Sine is collecting informally to really inform how are you going to then create training for participants specifically, and then later on for the different staff?    Yeah.    We're starting slow.    So, quite frankly, we would start slow.    So, start with a few low-hanging fruit kind of tools and build from there.    We do have a robust data department, and so our data department would be involved in collecting the relevant data, which I'd like to do because I think this could inform how our agency approaches AI as a whole.    Do you have a question?    Do y'all currently have an AI policy?    It's    We do.    It's one paragraph at the end of our employee manual, which no one ever looks at.    I found it because I was being proactive in trying to send my team some updates that I noticed the handbook, and I was like, what is this?    And that's how I learned that we're only supposed to use co-pilot.    There has been no explicit announcement to the organization.    You don't probably have the answer in that, but how would the policy inform the integrating of the AI curriculum?    So, listen, for now, I'm following the policy, right?    So, for now, we're using co-pilot.    We're not entering PHI.    You know, those are basically the two things that are in the policy.    I would like to integrate the IT team and have their full support so we could work in partnership together on that.    After all these questions, how can this chart support what you want to do is you produce?    All right.    So, I didn't know what the chart would be.    I will be terrified.    I you money, anything.    I would like access to consultants, free consultants.    if granted this, I would like to have some free consultants review our policy or, you know, departmental policy and practice and curriculum.    We prefer to call ourselves pro bono, not free.    And if we are free, we're free as in puppies, not free as in kids.    We're a big problem.    All right, okay.    All right, charts, this is great.    This is fantastic.    All right.    Each of you, you have 15 seconds.    You have three votes.    It is time for the showdown.    So it's either green light, yellow light, red light, and why you're giving that rating.    You have 15 seconds.    Each of which of you's ready to go first?    You know, it's green light, why?    If you don't do it, it'll be too late.    You know, because you are serving the clients.    And that's a...    Thank    But to his point, definitely, like, starting now in any aspect that you can.    Daryla?    I go green light to the idea of having pro bono consultants to help you out in the process.    And understanding that that is what you are asking for.    So to that, absolutely, yes.    You already have done some of the lead work that can help the consultant to guide you better, you know, down the road.    And that is it.    Daryla?    I'm actually going to give you a pit stop.    It's all different, but here's why.    I think you have the right space in terms of, yes, use AI, and clearly it's going to be a big boom to your organization.    I think you're doing a lot.    I think that people are already all over the map.    So what does it look like for you to actually be able to say, what is one tool?    Like, pick one thing that you can actually use to be able to help your team maximize their efficiency and go hard on that, rather than introducing a whole bunch of AI tools that people may get lost in.    All right, it's IKEA.    Very quick.    Greenlight?    Because I can align with the needs of the organization.    And also, I feel like, like, you know, said, if you don't start, then we won't ever, like, it'll be too late.    I also feel like even though you didn't fully have an idea, like, I think talking through it and us asking the questions help you to say, okay, this is exactly what I'm looking for.    So I feel like we were able to, they were able to, they asked questions to guide you to that answer.    So.    All right.    All you.    right.    got All right.    All right.    So, our next group, let me get on my tabs.    New York Department of Small Business Services, are you ready now?    And do I have your deck in the community?    Let me take a look.    Let's see.    Let's It's the SBS presentation?    Yep.    Okay.    All right.    Are you ready?    Yes, we are.    All right.    Your timer starts now.    Next.    The Citywide Workforce Opportunity Division of the Small Business Services Department manages the Workforce One Career Centers.    Next slide, please.    That's the largest Workforce One system in the nation of its kind.    We work with a lot of businesses that rely on us to recruit for talent.    Every time that a new business comes to us, we need to bet to make sure that they're safe for our clients.    We spend about 30 to 60 minutes manually verifying that that is the case.    That represents about 44 workdays a year.    That also represents a big bottleneck because we get no referred clients to them until they're betted.    And I'll...    This is done manually and is hindering our ability to reach our goals on FIT.    You're down to a minute.    Okay.    So the why is that we're falling short.    The current manual replication process puts us in danger of achieving only 44% of our annual hiring goal.    Organization impact.    It solves W, which is Workforce 1 referrals, delays client hires, and frustrates CWO, staff, and partners.    The bottleneck is choking our core function.    This isn't just inefficiency.    It's actively preventing us from achieving our mission-critical objectives.    Next slide.    So our solution, the VibeCheck.    And this is an acronym for verifying if businesses exist.    Now, this is through the use of workflow, CWO, staff, copy business details from Microsoft, Dynamics, CRM.    we put it into the co-pilot prompt called VibeCheck.    Yep.    And then VibeCheck.    VibeCheck.    It a verification report for CWO to review.    Output would be Confidence Score, Summary of Sources, the Human-In-Loop.    yeah.    So how are going to do this?    We need to get buy-in from executive leadership at our agency.    The budget ask is going to be very minimal because we're already on a Microsoft license.    Staff time will probably be about 40 hours of IT and data resourcing.    training should be very simple.    Really only an hour it'll take to go through the process because it's really relying on Microsoft Co-Pilot.    Where we're anticipating the most challenges is getting policy approval.    We're budgeting three months for that, navigating both agency and city AI policies.    But if we can get through that, we can navigate the policy hurdles and really implement quickly.    So we're going to accelerate our mission.    We're going to hit our goal of at least 75% of our annual hires.    We're going to assist our staff to make sure that they've got one less administrative task on their plate.    And we're going to satisfy our workforce one and employer partners to make sure that we're not just powered by AI, but also powered by good violence.    Yay\!    All right.    All right.    Hello?    All right.    Let's go.    So I know that you said that it's only going to take an hour for the employee to be trained.    Is there going to be leeway when it comes to that?    Because everyone doesn't have the same learning speed, or is there going to be options for how they can actually take the training or receive that information?    We want to make sure that the folks who are accessing these tools already have a knowledge and a literacy and AI platforms, rather than just throwing them into the deep end.    So they'll have to have undergone some level of AI training.    We anticipate it only being an hour, because effectively we're showing them the actual prompt that we want to put within the Microsoft Research Assistant.    And once they run that a few times, it should be very easy for them to practice that and implement it.    A few questions.    The first question is, how are you going to ensure the output is always accurate and reliable?    The second question is that, if you have a staff member who would want to do it the old way, newcause You can debate that We    What would be your response to that?    I'll talk to your second question.    And actually, we have someone here who does the manual process that would be valid, so she can definitely talk about the frustrations with it.    To your second question, like, I think the time saved in terms of being able to use an automated process would prevent our staff from going back to the old ways.    It just requires so much internet sleuthing, detective researching, like Googling, looking at different state databases, looking at platforms like D\&D Hoover's, Zoom Info, which just takes a lot of time.    Can you repeat your first question?    And I can stay with the first question.    think that, first of all, there's a human on the law, which is led by a human just outnumbered by AI.    And secondly, we are going to include a verification process as part of problem.    Thank you.    I think I'm a little confused by what you are actually.    So when it comes to you're verifying whether businesses exist.    Why isn't a simple Google search not the same thing as this, like, research tool?    Yeah, so there's many, like, small businesses, like, let's say, like, Ghost Kitchens, for example, that we can't verify that it's an actual storefront or place.    This is, like, place operating under Uber or some other company.    So it's a lot more extensive research.    We can't find their done somewhere because they're not registered.    Their tax ID number, which is another thing because they're so new.    And any Indeed, quote, job postings, we can't find that either because it's also new.    So using AI would make us, make this work so much more easier because for jobs like that, it might take, like, up to an hour, two hours just to find that they're actually.    And it would help Valerie crawl other sources that she may not be aware of, right?    Okay.    Okay.    Yeah.    No, you go ahead.    It's a little bit, you know, I was just curious, like, how many businesses a year or a month that that's inaccurate, that don't exist, it's a creative object.    Okay.    And then secondly, like, how do you create the tool that allows you to, like, you know, there might be a new business that might not have all the information up that you're not, like, ignoring or screening past, you know, that could, like, possibly join you up.    Yeah, so that's why, like, AI is so important.    Like, it researches the whole internet and not just, like, the surface.    Maybe we'll go, like, through the first, second Google page.    After that, it's, like, it's a lot of information to take.    So, yeah, that would almost want to go on.    Yeah, we're seeing hundreds of small businesses pop up all the time.    it'd be anything, like she said, a ghost kitchen or even someone, like, opening something within their homes, right?    And for us to be able to find that information quickly so that when they're coming to us with needs of, like, oh, now we need to hire staff for this kitchen, you can easily connect the job seekers that they're looking for and the strong candidates with those opportunities.    I have a couple.    One dimension that you will use this with those who already have some kind of knowledge.    So, how are you assessing that knowledge and what are you doing with it?    We were not already ahead of the curve.    Are you leaving them behind?    What else is that going to work?    And then you mentioned the timeline, which we know the city from very slowly.    So can you go through that three-month process of approval?    That's like a miracle.    I mean, yeah, we're trying to be very optimistic and aggressive with our timelines.    But I think three months or a quarter should be enough to get buy-in from our deputy commissioner, our first deputy commissioner, and our chief technology officer.    Ultimately, our commissioner is going to make the – is really going to pull the trigger of whether or not we're going to implement this because we have to fall under the citywide AI policy and not just what our agency is trying to do.    What about employee training?    Yeah, training, I think, is really important.    You know, if we could obviously have people like Valerie and other staff members attend something like this to have that baseline, I think what's going to be great is that Valerie can now bring this to the rest of our team and kind of show them and like kind of train the trainer model of like what you should be doing, what's the responsible use of these platforms, what are the prompts that we should be putting into this.    AI Research Assistant, and making sure that we're always having that human in the loop, as Aaron was mentioning.    All right.    That is the end of our time.    Thank you, everybody.    All right.    So, we'll start.    We've got two minutes.    What are our votes?    Is any of you ready to give your verdict?    I'm agreeing.    I think it's a very specific, like, solve that y'all have.    You've identified where there's a lot of of hours that are not being used as wisely as they could, and I think it's really smart.    I think I would just be careful about how quickly you go from essentially something that's all manual to something that's all automated so that you don't have the individual skipping over steps completely.    So, make sure that you build in what is the check and balance to make sure that they're not just putting it into AI, spitting out whatever it says, and then calling it in.    But I think it's a great solution.    There's lot of time.    Thanks.    I the idea, it's really tangible, something like you're not implementing AI to do too much, but something that you can do right away.    love the fact that you haven't even said how much time it takes.    I would say, make sure, like, part of the process for intake is, you you have to do some manual verification still, and create a guideline that goes out to the dose.    Yep.    Zakia?    You can go ask Kinos.    Can I ask a question?    Maybe I missed something.    Well, only have 44 seconds.    But is it possible that a business has no digital footprint at all?    So then that would have to involve us getting on the phone, tracking things down, going into neighborhoods, and really trying to find, like, other solutions where we can actually have confidence.    And if we can't find that confidence, we won't work on that business.    Okay.    Green?    All right.    All right.    Anything to, you know, accelerate the city.    I mean, I'm going to be a digitatracker.    I did like the idea a lot.    I think that for me, as someone who's not that tech-savvy, I'm a little nervous if I was in that role or in that position to have that pressure to, like, hurry up and learn the AI system and then transfer to learn the new system that will be implemented.    But that's just a personal thing.    A bias.    Yeah.    right.    Oh, I like it.    All bad.    Thank you, everybody.    Great test.    All right.    All right.    Consortium for Worker Education.    I want to point out that no one asked that what they were asking.    And I was going to say, also, I didn't.    was unclear.    No, I didn't I didn't hear it because they just wanted to accelerate the process of verification and they wanted to implement the system that allowed for that.    That's what I, that's what I wanted to want.    I wanted to.    Oh, man.    I thought I got to held to a different standard that I had to ask these.    She had to go first.    Hang on, everybody.    Hang on.    It's deal.    Okay.    Okay.    This is, again, like a fault in the exercise design.    The very first time we ever did this was like, I don't know, 10 years ago or something.    And we were asked to do a thing on fundraising for technology specifically.    So we did a shark tank where people would pitch their funding requests for a technology project.    And then the sharks were playing the roles of funders who were either going to fund and they had a specific ask, like $50,000 to do this.    But we were not that clear about making a specific ask.    The intention, just so we're clear, was do you basically think they're ready to do it and that doing it is a good idea for them in their current state, right?    Is it solving a meaningful problem?    Have they demonstrated they have the capacity to do it?    they thought through the challenges?    Do you essentially approve, thinking of you as the board of the nonprofit or something like that?    That was our conception, but we weren't.    They very explicit about it, but the remainers who go, if you want to be very specific with an ask, that's okay, but in the absence of that, what we're looking for is, you know, do I think you can do this and that you should do it, or do I have reservations about whether you can or whether you should?    Or whether the project needs some refinement.    Yeah.    Okay.    that's the little ground.    It's just...    Did they see the list of the list of the chart ratings?    It's only sent to us.    No.    Oh, okay.    Because I feel like that would make it more clear, like, definitely my kit stop was, like, suggestion for refinement.    Not that what you had wasn't good, I just think you have to polish it to get it down to, like, one thing, which is why.    and theirs was, like, I feel like very specific, that they're already going to kind of use the system that they have.    No, I hear you.    I'm not saying to you specifically at all.    Yeah, yeah, yeah.    More than one person said I didn't know.    That's I was asking for, because I didn't have a, right?    So, Consortium, are you ready to go?    You're ready.    You're there?    All right, do I have your, do I have your presentation?    CWE?    There, there you go.    All right.    Could you start off?    Did you just start slideshow?    Can you start on page two?    Okay, so that's, no, go up one.    Go back one.    That's the link if you want to follow along on what I'm doing.    Good man.    All right, you ready to pitch?    You guys ready?    Yes.    Go.    Flight eight.    Keep going.    Going.    Keep going.    Keep going.    There you go.    Stop.    Go up.    One.    Okay.    So as a teacher, you generate a lot of data.    And one of the problems is that by the time you finish up generating your data, you're too tired to figure out what you want to do with it.    Go down two slides.    Actually, stop right there.    So I created a prompt to analyze the data.    Go down one slide.    And then one more slide.    Keep going down.    There you go.    Go up one right there.    So, for example, 101, looks as if that person failed the class, but in fact, they had a problem with data literacy.    They didn't have access to the internet.    So that was an immediate remediation target.    That's an example of a metacognitive act.    Looking at the data, what does the data mean?    Second thing here, this is a heuristic.    Invariably, in my classes, I've got a bunch of knuckleheads and I've got a bunch of brainiacs.    Here's a way to pair and share them so that they're all actively engaged in my class.    Next slide.    This one here was important because it's probably that there's a problem in the end.    Answer key.    So that's something I had to go back and evaluate.    If there was one thing I had to reteach, would be this segment because there was a lot of scatter in terms of the data.    So those are all examples of how you can use a GPT to do the metacognitive analysis.    You can go back up to slide six.    Keep going up, keep going, keep going, keep going, keep going, keep going, keep going, going.    Down one more.    So this is the process.    So at our next union meeting for our UFT chapter, this is already on the agenda.    It's going to be proposed that we want to create our own cognitive agents, do this sort of work.    If our chapter agrees, then we're going to move forward where CWE will pay for our members, our most digitally savvy members to build the cognitive agents.    Finally, will be, every year we have a symposium, which is where it will be released.    Next slide.    We've got 20 seconds for that.    Next slide, please.    Cognitive agents can support our instructors in applying metacognitive analysis and characteristics to our students' artifacts, their homeworks, allowing us to become more creative, developing, individualized learning plans for our students.    Thank you.    My first question is, can you clearly state the problem for us?    We teachers generate a lot of data, and by the time we finish generating that data, our brains are tired.    We've to move on to the next unit.    We've got to move on to the next thing.    So being able to take the data and being able to use a cognitive agent and say, look, these are probably the things you want to focus on.    For example, student 101\.    What's the problem with student 101?    Your entropy is probably messed up.    So instead of taking the time to actually figuring it out for myself, the cognitive agent can do as well.    How are you going to match?    the success of the project.    Can you go back up to the one that was...    Okay, yeah.    Go back, go up, go up, go up, up, right there.    So let's go down one.    So at the end of the symposium, there's going to be during symposium, there's going to be a pre-assessment, a post-assessment, and based upon those, that'll be the basis for a end of the month post-mortem of the symposium, where we'll then figure out metrics for measuring how successful it is and also next steps forward.    You mentioned this, that you were going to be bringing this in front of someone, and you said it was already on the list.    Can you say more about that?    was already on the agenda?    Oh, our next union chapter meeting.    I talked to the chapter, our chapter leader, and he said, okay, yeah, we're going to put it on the agenda so that...    All of our instructors buy-in.    Either we vote it up or we vote it down.    If we vote it down, this goes in the garbage can.    If we vote it up, then we move forward on.    We already have the buy-in by the instructors, which notoriously are laggards when it comes to bringing in new technology.    And when it comes to their knowledge, you would say, like, for instance, the data that you were showing us is less familiar to us, but the data that you were showing on the screen, how familiar is your audience with that type of data?    Teachers know how to use spreadsheets.    That's how we've got, you know, student one, student two, student three on the rows.    Here's their first homework assignment, their second homework assignment.    So we're starting with, and that's what the templates are for.    Okay.    So that's like a pretty standard way of showing that data that they're used to.    Also, back on the map, that's one of the things we're going to do is we're going to design three templates that they will then, we link to the chat GPT.    Okay.    But that'll, again, the instructors will build those templates.    So they don't use that standard then.    There's different standards.    There's different ways that they pull out.    It depends on your teaching style.    If you're like me, you're going to do a spreadsheet.    Gotcha.    Multimodal and qualitative.    Okay.    Thank you.    Yeah, think you should try to just answer that.    was kind of wondering what tool you were going to use, like, to bring agents.    OpenAI was where the prompts will be iterated on.    And then that will be in Copilot.    Well, in our Microsoft license, you open up Excel, there's a Copilot button.    You bring up, for my case, the spreadsheet.    You click on Copilot.    You paste the prompt in.    That's a little awkward, but I was going to do API keys, but I decided against that.    So, that's still a little clunky right now, but hopefully we can streamline that a bit forward.    Darlie's my supervisor, so I don't know if you should.    Oh, so she's not allowed to talk.    Okay.    When it comes to, you said this is on the agenda.    So, when you think about, like, what we could potentially share with you.    you.    you.    you.    Thank    What do you think is most critical that you might want to understand about how to present this to get to where you want to be?    Like, what kind of question?    that's a toughie because this is a union UFT chapter.    Yeah.    So usually at our UFT meetings, the last thing we want to hear are management perspective.    want to talk about what we personally feel as instructors teaching our students.    So it's like a lawyer going to a biker bar and saying, could someone give me a light?    mean, it's just a clash of cultures.    Okay.    So the audience that you are presenting to is very different.    The people who are making the decision is very different from the user.    Is that accurate?    No, the user are the instructors.    Yeah.    The instructors are building the cognitive agents.    Okay.    And then from that, obviously, we have to bring it back.    CW will have to fund it.    So there probably has to be a meeting or a meeting of the minds there.    But the instructors.    Agree to it, create the cognitivations, and then hopefully we'll continue using them moving forward.    I know that y'all probably have.    Just one more.    Who do you think is going to be your most difficult stakeholder to convince?    Without being discouraging, people and teachers that are in the 60s who have been teaching for 20, 30 years.    Okay, thank you.    Thank for your time.    All right, Sharks, you got two minutes.    Do try to stick to 15 seconds when you give your vote.    Who's ready to give a vote?    I'm going to say slow ahead.    Honestly, just there was a lot of data.    Like, looking at it in first place, I was unclear exactly what she was pitching at first.    But I do, through the questions, I do like the strategy that you put out.    It's more about, like, understanding what tools are used.    And I know, like, working with Stern Daddy, you got to...    But it's only because that I don't know the profession enough, so I don't understand the pain points enough.    It's a lot to digest, so it has to do with the way of presenting of the information, I think.    I'm going say slow ahead.    I like the idea a lot.    My mom was an educator for a long time, so I do see where, you know, that the older teachers may be harder to convince, but I think that it just was confusing for me because we were flipping through the PowerPoint, and I couldn't really fully, like, if it was just in sequence, it would be easier to understand.    Yeah.    Yep.    I'm also slow ahead.    I think you have a really great idea.    I think that what kind of just needs to happen is what we think about your audience and think about how human beings are.    Just, like, take in information and make it really tailored to that.    You probably had to do more explaining with us than you will with the audience that you're presenting to.    So I think that's in your favor.    And then, yeah, just go in order and give your pitch.    And, yeah, you sounded very knowledgeable, definitely, of what you were talking about and the time that it would save.    Can I say something?    I'm not voting, obviously.    Anyway, go ahead.    Keep in mind that CWB, you have to get approval for that.    We don't have any policy or anything like that.    I will smooth the flow for you as much as I can.    But I also think about some of those older, not even 60, you know, the ages, like, 20 years more than that, to move on.    All right.    Thank you.    Real quick.    Yes, definitely applause.    Thank you.    I would honestly say one thing.    At some point, I think it was Teddy Roosevelt about, like, the gladiator in the arena.    Like, it's easy to sit outside the arena and, like, say things, but unless you're in there in the muck and the dust and everything, like, keep your mouth shut.    So I recognize that.    And you got up and you did the pitch, and I commend you for it.    We gave you the five-slide pitch deck for a reason.    It really helps when you're presenting to people to organize the thoughts in a way that doesn't require – I think there was a lot of overwhelm in the way the information was presented, which, in my view, is an obstacle to you getting across, I think, what was a very effective idea.    But it's unfortunate, but the reality is that presentation matters, especially in situations like this.    if you are going to – One last problem I had with your five – I put the first five slides where you're format, but I didn't see where I could put, you know, what this metacognition, what this jurist is on.    And you guys don't have a – you're not going to teach you background.    Yeah.    So I really had to start with basic – if this were the teachers, meaning I – Yeah, that's a big assumption.    a    Knowing the teacher, that is a ginormous assumption.    I know them by working with them for way too many years.    You need to make it digestible for them as you think it needed to be digestible for us.    I want to say one last thing.    Last word.    The way you started off was amazing because the way you was like, by the time we see all the data, I was like, word.    I'm looking at that.    That was a good pitch.    All right.    Thank you.    Thank you.    All right.    Well, I see we need at least like 20 minutes for the end.    You do so good.    I know.    We'll do one more for sure, but I don't know if we have time for two because we're going to take it right to the end if we do that.    All right.    Let's see your everybody's because I really.    All right.    They're great.    I wonder if we.    You.    You.    Okay, what if we change the rules on the sharks right now?    Getting our luck out now.    We can introduce it to like three minutes.    Okay.    minutes for the sharks.    Oh, yeah.    Three minutes for questions.    didn't even say, give them two minutes.    And maybe you can kind of just waive your decision.    Yeah.    Okay.    I do not.    All right.    So if I need the co-op career policy pal, and you guys want to set your own timer so you know how much time you have left?    I don't have my phone on me.    It's over there.    How long do you have two minutes?    Yeah.    Yeah.    Give yourself, give yourself two minutes and 10 seconds.    Okay.    When you hit start, give yourself two minutes and 10 seconds.    That's what I've been doing for everybody.    Wait.    It's not fair.    Damn thing I'm bad at this.    Two minutes.    See, not everyone.    I have the right.    Okay, good afternoon, everyone.    My name is Arvin Tanglin.    I'm Strategic Policy Manager at Co-op Careers.    Just a quick info about our mission is to overcome underemployment through digital skills and peer connections.    So, Sharks, today we're here to solve one of Co-op's quietest but most expensive problems.    It's the kind of problem no one budgets for, but everyone pays for it.    We call our solution PolicyPal, and it's about to cut through HR chaos like a hot knife through butter.    Let me show you exactly what we're talking about.    Next slide, please.    Right now, HR knowledge and SOPs at Co-op is a digital scavenger hunt.    Policies are buried inside PDFs, inside folders, inside more folders, and guess what?    Nobody can find anything.    So staff do what staff always do.    They search, fail, give up, then they ping or slack HR.    And then you wait.    That cycle happens about 30 to 50 times per week.    That's not a small week.    That's actually a flood of last time.    And it's holding us back.    So I'll tell you in .    So here's the truth.    Every repetitive HR question is time stolen from strategy.    in a growing org, the difference between scaling and stalling is whether your systems can keep up with your people.    Right now, co-op is running a race in manual mode.    And tribal knowledge, that's great.    Until you hit 80-plus staff, and suddenly no one knows where anything lives.    We're bleeding time, efficiency, and slowing down the mission.    But we're not here to complain.    We're here to sell you the fit.    Correct.    right.    All Three spaces is how we're thinking of rolling it out.    So essentially.    Okay.    Three phases.    You're down to like 10 seconds.    Three phases.    Let's pay attention.    Three phases.    So the first one is having the policies built in.    into what we are going to have, our policy pile.    And then the second phase is then having everyone have access to it.    And then the third phase, okay.    And then the third, I'm like, I'm going by memory.    Third phase is getting some buy-in and having people have a space where there's like ongoing feedback that we can have people like kind of test out what we rolled out and see if we can do it in a more.    more expanded way.    So the goal here is to have something low-lift, high-impact that makes it goals from how do I get this or that to, okay, wrapping it up.    There was no cost associated with it.    And yeah, the impact is time saved is more culture.    Time saved is time that we gain in doing innovation and building culture.    All right.    All right, Charts, three minutes to ask questions.    Let's go.    Yeah, so y use Google Drive, so y'all have, like, the Google Suites.    Just want to give y'all a heads up.    If y'all go to, like, the Google Drive, you can ask Gemini those questions.    So, like, that might be a little short, you know, thing you could do, but the idea, I think, is how that's for you.    What is your buying procedure internally from your peer supervisor or somebody who involved?    Yeah, I think we are very AI-curious, so I think that we would have the buy-in.    I think we just have to be able to show folks, like, what's in it for them and what, you know, there were some technical difficulties, but in what's in it for them is more so evolving the pain point where it's, like, where do I get these specific policies?    Where do I go?    Who do I go to?    And,    The point that I'm making is we have the buy-in in the sense that we are a very AI yes kind of organization.    What we want to do is make sure we show what's in it for the organization as a whole, how can we practically apply that?    And a lot of the questions that we get is like, how do I do X, Y, and Z?    And this would serve to kind of be that like source of truth that makes it more tangible.    Yeah.    And if you're asking about like who makes the decision, I would say that it's going to be a combination of like the head of the talent team plus the technology team and then the executive team.    I think what's on our side is this cost zero dollars.    And ultimately, it's just like we're trying to make something that's complicated faster for zero money.    I know that you said that this would free up time for more innovation.    Are you saying innovation?    within HR to work on other projects?    And is there going to be, like, a list of projects that they work on?    Because I think that they may, in HR, they may feel like, what do I do if I'm not helping when it comes to, like, policies and informing people of that information?    So how would you guys tackle that?    Yeah.    We're HR.    But what I would say to, like, specifically address your question, if we're not spending so much time, you know, answering the same question, but in multiple ways, we can then add that time to adding our expertise in, like, or like, hey, you have this workflow that you're working on, and it's not working.    Now I can add my creativity to that, because I'm not spending almost 50% of my time answering the same questions.    And then that leads to your team having, or any team, having more space for growth, and then keeping in that operational component, that development component, or acquisition.    So I think it's less of    about like, hey, what are y'all going to do with the time that you just gained, and more about how are you going to repurpose that time?    That's a question.    How are you going to use the data that you have?    The data that we have?    What data do you have for a week?    Time is over.    Okay.    We have the files and stuff that lives in our G-Drive already.    Yeah.    So it's already been uploaded.    We've been beta testing this internally already.    Yeah.    All right.    So green, yellow, or red?    Let's go with Zykea first.    Oh, you don't want me to go first.    Carlton.    That was that look.    Sorry.    We got a green light for Dinos.    We got a green light.    got a green light.    Zykea, you going to be a detractor?    not today.    It's our first day, bro.    That's Ariana.    Get yourself a good night.    I think it's been going on green light.    I'm sorry for our team.    that's good.    What now?    I'm sure I did.    I did.    I voted for my own team.    I'm sorry.    It was an accident.    Okay.    I'm supposed to be honest.    All right, let's be learned about this, by the way.    Don't tell your AI to help you make a two-minute test, lie to it, and say 90 seconds.    This is not real.    AI doesn't understand how long it takes to get out there.    All right, Kim, you want to do the last one?    want to do Department of Aging?    All right, Department of Aging, are you ready?    All right.    We're going to do this.    Vickity, splickity.    All right.    Do I have your deck?    I think Dipta.    I sent it, I think, this morning.    saw it come in earlier.    It said Dipta Pitch Deck or something like that.    Dipta Slide Deck.    Yeah, Dipta Slide Deck, yeah.    Ah, SharePoint.    Yeah, I ain't going to play.    Yeah.    Oh, no.    Yeah.    yeah.    yeah\!    Oh, Yeah\!    You know, it's always good to be ready to do it without the slides.    You know, it's good practice.    All right, let's go.    You're going to do it, all right?    Okay.    You're going to try.    Okay, here we go.    It's going to be relatively short.    I'm going to go relatively short.    Yeah, go for it.    Okay.    All right, sharks, everyone else, raise your hand if you know how to apply to become a, let's say, air traffic controller.    No one, right?    All right.    Our app is called Pitch Forward.    We created this in last week and we figured that with the ability to use an app to be able to first give it a, give you a resume, you upload your resume and answer 10 questions on what your barriers are, what your, what your barriers are and what your goals are, right?    What this app does is gives you a plan, like an IP, immediately.    To figure out what is the best way to figure out what's your plan.    So I don't know how to become an air traffic controller, but it'll tell you step by step what you need based on what you already have.    The problem that we're trying to figure out is figure out how to get rid of burnout.    figured out that 66% of our survey says that 66% of people deal with burnout for their job search.    And so this kind of addresses that situation.    So after giving you a detailed idea of what it is that's going to be your plan, you can then implement it.    We are the Department for the Aging, so we have people who are above the age of 55, and we figured that this could be a good tool to use in partnership with the staff here, whether it be the case managers or the job developers, to have a better idea of what it is that they're going to look like.    Most of our participants have difficulty figuring out realistic goals.    They may have an idea of like, oh, I want to become an officer.    Office-Aid or Secretary, but you see that they don't have any experience in that in the resume.    Plus, they don't have the ability to use the stuff on the computer, right?    don't, because of that, I think this is a good tool for us to figure that out together.    So, if any advice would be really, really appreciated.    We're sharks.    Thank you.    Thank you.    All right.    We're going to have two minutes for questions on this one, because we're really good.    Please.    My question is, I know that you said that you work for the Department of, I'm sorry, Aging.    Department of the Aging, yes.    Yeah.    So, because they're older, the demographic, how do you foresee them being able to use the app to- Good question.    So, yeah.    Wait, I didn't finish my question.    I know we've seen that, but how do you foresee that they'll be able to use the app, and also, are you going to have computer classes or, like, phone training classes in order to help them to get to that point?    Kari, could you answer this question?    Yeah, we already teach courses in digital literacy.    we even Okay.    need to my    Starting with, you know, using email and also using AI.    So my students are already using AI as an interview coach.    So they're not afraid of it.    They're open to it.    So we've got to buy in from them.    And with maybe a little bit of extra help in the classroom or a little bit longer workshops, we would be able to implement nearly anything because they're like little sponges.    Right on.    So you work for the Department of the Aging.    Is this the main, like, role of y'all's team?    Is specifically supporting people that are coming to the Department of the Aging to find a job?    The Department of the Aging is separated into different parts.    We are specifically a CSET program, which focuses on employment.    So we help people through, like, an internship to help them find employment.    Okay.    Yeah.    So they're coming to you to help find employment.    Correct.    Okay.    Anything else?    Yeah.    I'm just going to clarify.    So who is the immediate user of the app?    Is this the job developer because you've mentioned job developer, ¿verdad?    O is this the client?    My idea is the client, right?    Because it's easy to use.    You don't have to necessarily upload.    So if you don't know how to upload your resume, you can actually skip to the part where you answer the questions.    But again, there are participants who are not going to be able to even do that on an iPad on themselves.    So we can help them together to figure that out.    Go ahead.    Sorry.    No, it's for both.    Yeah, it could be for both.    Quickest data question.    What is your employment outcome right now?    Like how many percent of people do you get a job typically?    Well, because we're an internship program that changes of month to month, but is it like 30%?    a month.    Yeah.    Okay.    Votes.    Time for your votes.    Go.    No more questions.    Very darn it.    We got a slow ahead, a slow ahead, a slow ahead.    What are the hesitations?    Real quick.    I like the idea of that, but I know my grandmother acts funky when it comes to technology.    And yes, they're sponges, but they're    Also set in their ways.    So it's kind of difficult to kind of nudge them and make them use something they don't really want to use, especially if they've been in the workforce for 40 plus years and not using it.    Hang on, I got a call from your grandma.    What is that kid talking about?    Tell that girl then.    She might say that.    I'm almost a little bit between because I think if they're already coming to you, then they're clearly engaged enough to say, I'm willing to put in the work to find a job.    So I think it just depends on like how, how easy can you make this so that that way it does what you want, which is like decrease burnout and allow them to be able to potentially put fiber jobs faster or easier or something like that.    Did we post it in the announcement?    You can try yourself to see how difficult it is.    that's the one I think.    Yeah.    I think, I think the app is good.    Slow ahead because I know you still have some folks, so I know that there's still more to do.    I think it's a, I think it's a dope program.    I even think about like how you use it for.    All the people, but to me, I deal with the youth, and I have to do job placement, so I'm like, how do use it for myself?    So, I like it.    Yeah, thanks.    All right.    Thank you, presenter.    No, stay here.    can go back to about there if you want, whatever you're comfortable with.    Stay comfy.    Don't move.    You don't have to move if you don't want to, all right?    this is where we go, like...    Yeah, we're just wrapping.    Okay, so you do compass, and then I'll throw it in 60\.    All right, so just to reiterate, like, the compass framework, you know, it's not like it's the be-all, end-all, but I have to say I keep coming back to it in various situations with clients and in working and with myself when I'm struggling with something.    If you're familiar with the concept of, like, first principles, it, like, cuts through the noise of, like, what tool should I use or, you know, what prompt or how should I do this and get back to, like, what is it I'm trying to do here?    What is the...    Problem I'm trying to solve, and then helps you kind of structure that through in an AI-focused way, okay?    I will say it over and over again, this is a very weird technology.    It is very different than any technology we've experienced, very powerful, incredibly capable, but also weird.    And this framework, I think, helps manage that weirdness in a way that I really encourage will be helpful.    It seems like more work to think it through, but it is worth it, all right?    So, understanding your organization's reality, setting measurable AI goals, making your plan, which we worked on today, measuring it, is this working, is it doing what we want, are we achieving what we want, and then sharing with each other, sharing both within your organization, within communities, and so on, all right?    So, without it, you know, you're just doing the same thing someone else is doing, and you're not helping each other, and a million mistakes, but we're sharing Agile ballgame, everybody.    Thank you.    Without sharing, it's like, you're never going to get better.    It's all going to be, but it's picking the ball in a very disorganized manner and misestimating, thinking you can do 20 and really only do 5\.    You never measure, you never realize, oh, I only did 5, not 20\.    You iterate, you get better, you realize what you can be capable of, and that capability compounds.    All right, real quick thing from Daniel.    Am I the only one who's noticed that all those apps, supplements, and magic elixirs for getting smarter don't actually work?    In this video, I'm going to give you 8 habits that do work, 8 dead simple, science-endorsed techniques that will sharpen your mind the moment you finish this video.    Each one is rooted in peer-reviewed research and ends with a specific action you can try today.    So let's get started.    Strategy number 1, teach it to learn it, the Feynman Technique.    Richard Feynman was one of the greatest physicists of the 20th century.    He was responsible for breakthrough after breakthrough in some of the most complicated science in the world.    For his efforts, he won the Nobel Prize in Physics.    More important for...    For our purposes, though, he was an incredible explainer, and you can learn from him.    Feynman kept a plain notebook labeled, Notebook of Things I Don't Know.    His rule was simple.    If he couldn't explain something to someone else in simple language, he didn't really understand it.    Modern research backs him up.    In one study, students who taught a lesson scored significantly higher on comprehension tests than students who merely studied that lesson.    Teaching others forces you to process the information more thoroughly, which strengthens learning and leads to deeper understanding.    So, here's our first action step.    Pick one concept you learned this week, whether it's the causes of the Peloponnesian War or how to change the oil on your Subaru.    Then find a friend and take five minutes to teach them.    Do they get it?    If not, try again.    Hone, hone, hone until they understand, because that means you understand too.    Too shy to teach a friend?    Explain it to your dog, your mirror, or record a voice memo.    Seriously, it works.    I cannot agree with that more.    I think we probably talked about it in the earlier lesson, but, you know, Kim and I, our whole lives are based on the learn one, do one, teach one sort of medical model.    And I've literally come to believe that I am learning more at each step on that run, which sounds really weird that I learned more from teaching this class than I did learning the things and then doing the things that led me to teach this class.    But it really is true.    And so if you're not ready to teach someone else, good, do it anyway.    Like, it'll help you understand it yourself.    All right, Kim.    You know, we speak to you as the ambassadors of AI at your organization.    You have been appointed, you have this mission, okay?    And organizations need it, right?    How many of you guys have policies?    So, you know, and it may feel like, oh, my God, this is so daunting.    This changes every day.    How can I keep up?    Blah, blah, blah, right?    All the stuff we say.    Explaining it to people.    You know more than 95% of nonprofit professionals now, okay?    About AI.    All right?    So, and just think, like Josh and I were like, we seem like so far ahead, right?    We're not that, we haven't been doing this all our lives, right?    So we started literally teaching this as we were, as like ChatGPT was rolling off the presses.    So, um, Many of you will be ahead of us within the year.    Yes.    Yeah, indeed.    So, that is the fish, right?    So, it's pretty good AI fish.    Um, so, this is really to encourage you to go, you know, go forth at your organizations.    You're in a good position to bring this knowledge back.    Because people need to know this.    mean, look at every single project was like all your participants on some.    That level, you know, need help.    They need more, right?    And it's not like we have, like, nothing to do all day and we're running out of work.    So this can help deliver things more.    So, but in, don't be afraid to teach it if you don't feel like you don't know it yet.    I have one thing to this, Kim.    Like, part of this is what Kim and I have found over the course of training, if you can do it, right, is that it is very important to actually solve problems for people as quickly as you can.    So when we approach organizations and start working with them, you know, they call it quick wins or whatever you want to call it.    Like, it's very important to give someone a fish right away.    Like, they're hungry, they need help, they're in pain, so alleviate pain right away.    But also, I'm teaching you how to alleviate your own pain, how to fix your problems yourself at the same time.    While I'm doing that, I'm learning more about you, the nature of the problems you have, how I can better help you, how I can better help others, and I'm going to learn from you how to better solve problems for myself.    And then we're doing that all together.    But the reason it starts with the give you a fish, I have to say that is really important.    Try to help right away because that gets you kind of in the door, so to speak, and then people will start to work with you.    All right, sorry, it's very clumsy.    All right, do want to do the word cloud?    Do you want to get Mentimeter up or do you feel like we don't need to do it?    We'll do it after the thing.    We'll do it after, We want to do like a before-after word cloud, so many of may remember we did a word cloud in the beginning, and so just for a data point, we want to do it after.    Go ahead, Jim.    So, all right, so here's what we put forth.    Yes, today's the last day we're meeting here like this together, and it has been wonderful.    It's been one of the best.    Josh and I have been doing this for a long time.    Like, we might have been teaching AI for 30 years.    We've been working with nonprofits, doing a lot of capacity building.    I'm to say this ranks as really one of the best experiences.    experience.    Well, here's    that we've had, like, like, you know, they call this work, right?    It's really, um, yeah, this is an amazing group.    I don't know, like, what kind of magic, um, Justin, but, right?    So, I'll let you guys, so, and I'm honestly, so we put forth a challenge.    All right, we have a community.    It's not going anywhere.    In fact, you know what?    For all those policies, places without policies yet, have I got a treasure trove of stuff that I'm going to be uploading this weekend?    I'm spending the day at Mom's tomorrow.    My mom's 91\.    Um, and so, uh, I will have, like, a lot of time.    for her.    Huh?    have an app for Mom.    No\!    No\!    No\!    No\!    No\!    No\!    Um, um, and, uh, I'm going to be uploading a lot of stuff to the session four, okay?    We have, um, do's and don'ts lists, for those    I have a survey, right, that you can give, you know, at your organizations to other staff to find out what they're using.    That came up in a lot of those scenarios.    Like, what the hell are people using?    Okay, so we have a template survey for that.    It's in Google.    I can't figure out how to do it in forms.    But, so, we will.    Oh, sorry.    Oh.    So, 30 days.    So, know that there's more coming in the community.    Check in, if you haven't already, at least by 30 days and say how you're doing.    Okay?    It's going to be, like, getting around, like, the holidays.    So, you know.    At 60 days, we're going to have an office hours.    Okay, we did this with our TechSoup class, which was, I have to say, not as fun to teach as this, right?    In fact, we didn't really know how it went over, because it all remote.    was 200 people, but it was remote.    And we had, like, 20 – it was an amazing experience.    So come back and join us for office hours.    You will get an invite.    We're going to be working with Justin.    And then 90 days, 90 for 90, we're going to have a 90-minute session with you.    Okay?    This is continuous learning.    And God knows what's going to be, like, in 90 days from now.    Look at what, like, Google Notebook LM did last night, right?    So – all right?    Darlene just went, like, oh, like, we're doing that for you.    No, no, no.    We're doing it for us.    Yeah.    we're going to learn so much from you in 90 days.    Yeah.    Like, Carlton's going to teach, like, 45 minutes of it himself.    We're going try not to you train them.    All right.    So, anyway.    So we really love for you to come back.    And I think our mentee.    We're not doing that.    Okay.    It's popping up for We have the ongoing support.    I guess it's not ready yet.    Yeah.    Oh, I haven't started presenting.    Sorry.    I've got to present.    There we go.    Okay.    Oh, okay.    Do want me to get it for you?    Yes, please.    It's on that table.    But next to Kim.    Behind you.    Oh, here?    Yeah.    sorry.    It still says waiting.    Yeah, waiting for presenters.    I think she's not going to present yet.    I did present.    I did present.    In Menphi?    I did.    It's working now.    Okay.    There we go.    Skip the first question.    Skip that question.    We're just going to the one word.    So let's just go to the one word.    That's all we want for today.    It's one word that describes how you feel when you think about artificial intelligence.    All right.    And yeah, good luck to all you and do great work.    You're all, we've said a bunch of times, you're all just really, really amazing and doing such incredibly important work for the city.    And the people in it.    And And    And I can't imagine any other people I'd rather be helping.    So thank you all.    You're helping people adjust to this.    Happy holidays.    It's really not easy.    So thank you for dedicating your time.    So go forth and...    Like that non-experienced expert.    Yeah, that's really good.    Love it.    I mean, that's...    Like, that's, like, perfect.    No, it's funny.    So I put that one in.    I was in a conversation just early this week with some organizations about more about the fear around AI and everything like that.    And, like, they were talking about what are the benefits.    And I said, you you could basically be an expert with no experience.    And one person was like, well, that's perspective, right?    Some people, like, that's scary to some people that you could be an expert.    But, like, come on.    Like, if you need to know a tool and you need to know something, like, you got the tools to help you do that real quick.    Like, know, why you...    You know, bridge that gap.    So, I thought I did.    Beautiful.    Yeah, I mean, the upshot of something that's changing so fast is like, that's what we said in the first one, right?    It's, you know, and even if I, even if we were today, unless we're working just as hard as all of you, you know, in a month, we're all in the same place, basically.    So, I saw a hand in the back.    Someone, you want to say something or just stretch it?    Listen, get out of here.    It's Friday afternoon.    You all are awesome.    Be well.    Thank Thank you.    Thank you.    I've been trying to tell you that I like that.    I'm going to have to do that.    Because I have a PS that I'm going to have to do.    Thank you.    like.    Thank you.    Thank you.    you.    No, we have not been in chat.    That's, think, what it is.    Yeah, like, we have over.    Yeah, it's now available.    Thank you.    So, I mean, billboard.    I'll see what I'm just going to look at.    just don't know if we're happy about it.    Yeah, that's what I'm sure.    Yeah, that's that's I'm sure.    Yeah, that's trying sure.    I'll put Facebook back.    Uh, like, can you get that?    All right.    All right.    All right.    All right.    I'm just like, I have a question?    I don't know.    I don't know.    I don't know.    I don't know.    I don't know.    I don't know.    know.    I know.    I don't know.    I don't know.    I don't I don't know.    We'll break it.    We'll    I would say, I would say, so, we have that long, but it's so great, yeah, there's so many tools, I'm like, there's something more blue that just came Oh, thank you, thank Oh, Oh, cool.    Yeah, the last time, awesome.    Yes, Suno.    Suno.    Okay, go ahead.    Thank you.    Hey.    Yeah, yeah.    Oh.    Okay.    Yeah, just want to write like most short stories and then put it in and it just...    Yeah.    That's awesome.    That's awesome.    That's awesome.    Uh, hold on.    Wait, I have to just do everyone listen.    There you go.    Did he click or drop?    He's fine.    Sincerely, no, no, Exactly.    Oh my gosh, I don't feel like I have to wonder about it.    That is me.    Yeah.    Can I use it?    Yeah.    Thank you so much.    That plushy image is what I use for everything publicly.    Is it generally by AI?    Yeah, yeah, it's just what I use instead of my photo.    my God.    It's not like my photo isn't online, but just to like keep it less online.    Thank you so much for the...    Oh, thank you.    There is so much comments.    I'm so glad.    Yeah, yeah, yeah.    Our organization does not really have an advocacy, but I may be able to register.    I just had a quick question for you.    I was trying to figure out what to do next, because I'm thinking about, I'm working as a computer instructor, trying to think about doing some more.    Oh, okay.    I mean, if you want to do AI stuff, it's funny.    mean, no problem.    You're a sucker.    trying to do AI stuff, that's a great, I don't want to know.    Are you a from RIT?    Me?    Oh, no, my son, yeah, the water bottle.    My son got it on a college winter, and it's like a water bottle.    We should do an in-person 60-day office hospital.    Oh, okay.    I almost went to the RIT.    Yeah, yeah, my son had my car to produce.    Did you study engineering?    Comparison high.    Okay.    Yeah, so.    Okay.    How do you like North Carolina?    It was quite different compared to my city.    was like a big tempers, and for here, because I went to the community college first at LaGuardia, so we have four buildings, that's all we have, but at North Carolina, you have a big.    You have a football court, you have a football court, a lot of different things, but it's just a different experience.    Thank you.    And you grew up in the city?    No, I grew up in China, but I am 17 after graduating high school.    Thank you.    It's a man.    I'm here.    Okay, yes, do you want to join us for office hours?    For humor.    Thank you, Eric.    Thank much.    Thank Joke us.    Yes, we'll show.    you, yeah.    Just don't ever see you in the future.    Thank you so much.    by all means, reach out to me on LinkedIn.    That's all I'm happy to chat.    Thank you.    All right.    Thank you.    Thank you.    Thanks.    I didn't have a jacket.    I probably threw it somewhere, but where, I don't know.    see you in person for the sixth time.    In the 90, they said they'd be happy to do it here.    Okay, well, probably, let's think we were probably going to do virtual as originally planned, I know, but up to you guys.    But if we wanted to do it, Ariana said they could do it here.    So it's totally up to you guys.    we do the 90\.    Maybe we can do virtual for the 60 and in person for the 90\.    So like, almost like, you know, build up.    Great, really.    Great job, guys.    Well, thank you.    So do you have what you need for the...    Yes, for the proposal, we're all set.    I just passed it along to our development person.    We're in good shape.    they'll do...    Yep, they'll all handle it from that.    All right.    Kim, is that your jacket?    Okay.    Okay.  
